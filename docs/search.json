[{"path":"index.html","id":"ma-500-introduction-to-r","chapter":"MA-500: Introduction to R","heading":"MA-500: Introduction to R","text":"FANUCHÅNAN 2024: 8/14/2024 - 10/04/2024Instructor InformationRegina-Mae Dominguez | dominguezr@triton.uog.eduOffice Hours & Location: Online Appointments","code":""},{"path":"index.html","id":"course-introduction","chapter":"MA-500: Introduction to R","heading":"Course Introduction","text":"markdown site include notes, guides, resources, Moodle central hub course well platform uploading submitting homework assignments. course progresses, site regularly updated ensure ’s helpful, easy navigate, accessible whenever need reference. resource designed useful, strongly encourage take notes personalized detailed study guide.","code":""},{"path":"rrstudio-installation-guide.html","id":"rrstudio-installation-guide","chapter":"R/RStudio Installation Guide","heading":"R/RStudio Installation Guide","text":"","code":""},{"path":"rrstudio-installation-guide.html","id":"installing-r","chapter":"R/RStudio Installation Guide","heading":"Installing R","text":"install R, begin visiting Comprehensive R Archive Network (CRAN) : https://cran.r-project.org/. Select download appropriate R binary package operating system— whether Windows, macOS, Linux. Mac users, please sure install correct package binary associated processor (e.g., Intel Apple Silicon).","code":""},{"path":"rrstudio-installation-guide.html","id":"installing-rstudio","chapter":"R/RStudio Installation Guide","heading":"Installing RStudio","text":"RStudio widely used integrated development environment (IDE) R programming. can download free version : https://posit.co/downloads/. Whie option use alternative IDEs, VS Code Rtools extention base R GUI, recommended use RStudio course material primarily demonstrated using IDE. ensure can easily follow along course content!","code":""},{"path":"r-scriptscode.html","id":"r-scriptscode","chapter":"R-Scripts/Code","heading":"R-Scripts/Code","text":"Writing clean, efficient, well-documented code important aspect course! Developing habits early crucial clear communication, effective collaboration,smoother debugging troubleshooting, error prevention. Therefore, assignments evaluated functionality also readability adherence coding practices. However, don’t stress much !!applicable, homework assignments, always submit:source file .R .Rmdsource file .R .Rmdraw data used (.csv .xlsx)raw data used (.csv .xlsx)cleaned/output data (.csv .xlsx)cleaned/output data (.csv .xlsx)code outputs (whether inclusive R script separate document )code outputs (whether inclusive R script separate document )","code":""},{"path":"r-scriptscode.html","id":"tips-on-cleanwell-documented-code","chapter":"R-Scripts/Code","heading":"Tips on clean/well-documented code","text":"’s style guide usually follow: Tidyverse Style Guide. ’s purely optional meant helpful suggestion, requirement. However, excellent resource getting started writing well-documented, clear, consise code.","code":""},{"path":"r-scriptscode.html","id":"example-code","chapter":"R-Scripts/Code","heading":"Example code","text":"","code":"\n#'\n#' Calculate percent change of means between two years\n#'\n#' @param dt data.table with mean outcome column\n#' @param old_year initial year\n#' @param new_year most recent year\n#'\n#'\n#' @return modified data.table with new percent change column and label column\n#' \n#' \nget_pt_change <- function(dt, old_year, new_year) {\n    # split dt to separate old observations and new\n    # observations\n    new <- dt[Year == new_year]\n    setnames(new, c(\"mean\"), c(\"new_mean\"))\n    old <- dt[Year == old_year]\n    setnames(old, c(\"mean\"), c(\"prev_mean\"))\n\n    # merge to create new dt and calculate percent change\n    pct <- merge(new, old, by = c(\"plot_id\"))\n    pct <- pct[, `:=`(mean_pct_change = (new_mean - prev_mean)/prev_mean *\n        100)]\n    pct <- pct[, year_pct_change := paste0(old_year, \" - \",\n        new_year)]\n\n    return(pct)\n}"},{"path":"r-basics-and-fundamentals.html","id":"r-basics-and-fundamentals","chapter":"1 R Basics and Fundamentals","heading":"1 R Basics and Fundamentals","text":"","code":""},{"path":"r-basics-and-fundamentals.html","id":"comments","chapter":"1 R Basics and Fundamentals","heading":"1.1 Comments","text":"R, can comment #. (markdown, # usually denotes start heading.)","code":"\n# comment here\n#' \n#' adding ' after #, allows you to enter multi-line comments\n#' \n\n# basic arithmetic\n1 + 1## [1] 2"},{"path":"r-basics-and-fundamentals.html","id":"directories","chapter":"1 R Basics and Fundamentals","heading":"1.2 Directories","text":"R sessions usually working directory associated . default location files imported saved.","code":"\n# check your working directory\ngetwd()## [1] \"/Users/rdominguez/Documents/MA500/ma500_fall2024\"\n# change your working directory\nsetwd(\"/insertfilepathhere\")"},{"path":"r-basics-and-fundamentals.html","id":"r-packages","chapter":"1 R Basics and Fundamentals","heading":"1.3 R Packages","text":"Base installation consists many -house functions commands, specialized techniques require installation packages. packages course (probably many ):ggplot2ggplot2data.tabledata.tableMASSMASSstatsstatsNote: using mac, development packages require install XQuartz XCode. issues come installing package getting package work, please let know can help !Find packages : https://cran.r-project.org/","code":"\n# installing packages\ninstall.packages(\"MASS\")\n# calling the package after installation\nlibrary(\"MASS\")\n# updating packages/all packages\nupdate.packages()"},{"path":"r-basics-and-fundamentals.html","id":"coding","chapter":"1 R Basics and Fundamentals","heading":"1.4 Coding","text":"","code":""},{"path":"r-basics-and-fundamentals.html","id":"variables","chapter":"1 R Basics and Fundamentals","heading":"Variables","text":"Assigning names values done R assignment operator: <- (opposed conventional = used named function assignments.)Note: R dynamic language, types values can easily changed. (type checks done run-time)","code":"\n# variable assignment\nx <- 4\ny <- x^2 + 2 + x\n# to output what y is (assignment does not print output)\nprint(y)## [1] 22\n# or simply just\ny## [1] 22\n# x is now a of type character\nx <- \"statistics\""},{"path":"r-basics-and-fundamentals.html","id":"r-data-types","chapter":"1 R Basics and Fundamentals","heading":"1.4.1 R data types","text":"numeric (double int) - number without decimal point (can contain NA)numeric (double int) - number without decimal point (can contain NA)character - grouping characters stringcharacter - grouping characters stringlogical/boolean - TRUE FALSElogical/boolean - TRUE FALSEvectors list related data typevectors list related data typeUse class() determine variable type","code":"\nclass(2)## [1] \"numeric\"\nclass(x)## [1] \"character\""},{"path":"r-basics-and-fundamentals.html","id":"data-vectors","chapter":"1 R Basics and Fundamentals","heading":"1.5 Data Vectors","text":"Vector: collection observations measurements concerning single variableIn 2021, average temperature Guam month 80.7 81.4 81.5 82.6 82.6 83.7 83.4 81.8 82.5 81.4 82.0 81.0.case one values vector NA, sum mean also return NA. sum(, na.rm=TRUE)Attributes: Vectors can attributes, names case.","code":"\n# Let's place this list of temperatures in a data vector.\n# creating a vector - numeric vector\ntemp <- c(80.7, 81.4, 81.5, 82.6, 82.6, 83.7, 83.4, 81.8, 82.5,\n    81.4, 82, 81)\n# this returns the length of the vector\nlength(temp)## [1] 12\nsum(temp)## [1] 984.6\nmean(temp)## [1] 82.05\n# assign month to each temperature in the temp vector\nmonths <- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"July\",\n    \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n\nnames(temp) <- months"},{"path":"r-basics-and-fundamentals.html","id":"indexing","chapter":"1 R Basics and Fundamentals","heading":"1.6 Indexing","text":"can call specific value temp vector referencing ’s respective name., can index vector referencing numeric index value.","code":"\ntemp[\"May\"]##  May \n## 82.6\n# returns the first element in temp\ntemp[1]##  Jan \n## 80.7\n# if I want the first 4 values, index with :\ntemp[1:4]##  Jan  Feb  Mar  Apr \n## 80.7 81.4 81.5 82.6"},{"path":"r-basics-and-fundamentals.html","id":"operators","chapter":"1 R Basics and Fundamentals","heading":"1.6.1 Operators","text":"Comparison:> Greater > Greater < Less < Less <= Less equal<= Less equal>= Greater equal>= Greater equal== Equal :== Equal :!= equal != equal %% (applicable vectors)%% (applicable vectors)Logical:& & | | ! ! NOTWhat month gives highest temperature?Let’s say want find average temperature summerThe average temperature:","code":"\n# get all temperatures that are higher than the temperature\n# in Aug temp['Aug] refers to temperature in August adding\n# temp > temp['Aug] inside temp[] means within the temp\n# vector\ntemp[temp > temp[\"Aug\"]]##  Apr  May  Jun July  Sep  Nov \n## 82.6 82.6 83.7 83.4 82.5 82.0\n# want temperatures that are greater than temps in August,\n# but also temperatures in the Fall\n\nfall <- c(\"Sep\", \"Oct\", \"Nov\")\ntemp[temp > temp[\"Aug\"] | names(temp) %in% fall]##  Apr  May  Jun July  Sep  Oct  Nov \n## 82.6 82.6 83.7 83.4 82.5 81.4 82.0\ntemp[temp == max(temp)]##  Jun \n## 83.7\n# if you would just like to extract the month\nname <- names(temp)[temp == max(temp)]\n# grab only summer months from temp vector\ntemp[c(\"Jun\", \"July\", \"Aug\")]##  Jun July  Aug \n## 83.7 83.4 81.8\n# OR define summer months\nsummer <- c(\"Jun\", \"July\", \"Aug\")\n# temp[names(temp) %in% summer]\nsummer_temps <- temp[summer]\navg_summer <- mean(summer_temps)\navg_summer## [1] 82.96667"},{"path":"r-basics-and-fundamentals.html","id":"vector-operations","chapter":"1 R Basics and Fundamentals","heading":"1.7 Vector Operations","text":"vectors, can utilize element-wise basic arithmetic.example, want add 2 degrees every temperature temp data vector, can define :Let’s print see looks likeNow, let’s see mean looks like againNow, degrees given Fahrenheit, let’s say want convert Celcius.formula :\\[\nC = \\frac{5}{9}*(t - 32)\n\\]t temperature Fahrenheit.Print temp celcius (notice still kept attributes temp)","code":"\ntemp <- temp + 2\ntemp##  Jan  Feb  Mar  Apr  May  Jun July  Aug  Sep  Oct  Nov  Dec \n## 82.7 83.4 83.5 84.6 84.6 85.7 85.4 83.8 84.5 83.4 84.0 83.0\nmean(temp)## [1] 84.05\ntemp_celcius <- (5/9) * (temp - 32)\ntemp_celcius##      Jan      Feb      Mar      Apr      May      Jun     July      Aug \n## 28.16667 28.55556 28.61111 29.22222 29.22222 29.83333 29.66667 28.77778 \n##      Sep      Oct      Nov      Dec \n## 29.16667 28.55556 28.88889 28.33333\nmean(temp_celcius)## [1] 28.91667"},{"path":"r-basics-and-fundamentals.html","id":"sequences-and-repetition","chapter":"1 R Basics and Fundamentals","heading":"1.8 Sequences and Repetition","text":"R -house functions allow create sequence values (repeat).using seq rep, can read help documentation using ?function R. pulls documentation example usage","code":""},{"path":"r-basics-and-fundamentals.html","id":"sequences","chapter":"1 R Basics and Fundamentals","heading":"1.8.1 Sequences","text":"Without function, easiest way create sequence intervals 1 using colon operatorFor flexible sequences, let’s use seqNote: always include number, number depending ’re number .Instead specifying number, can specify many numbers like length.- equally spaced.decreasing, set `` negative value switch values.","code":"\n1:10##  [1]  1  2  3  4  5  6  7  8  9 10\nseq(from = 1, to = 10, by = 3)## [1]  1  4  7 10\nseq(from = 1, to = 10, length.out = 20)##  [1]  1.000000  1.473684  1.947368  2.421053  2.894737  3.368421  3.842105\n##  [8]  4.315789  4.789474  5.263158  5.736842  6.210526  6.684211  7.157895\n## [15]  7.631579  8.105263  8.578947  9.052632  9.526316 10.000000\nseq(from = 10, to = 1, by = -3)## [1] 10  7  4  1\nseq(from = 10, to = 1, length.out = 12)##  [1] 10.000000  9.181818  8.363636  7.545455  6.727273  5.909091  5.090909\n##  [8]  4.272727  3.454545  2.636364  1.818182  1.000000"},{"path":"r-basics-and-fundamentals.html","id":"random-sampling","chapter":"1 R Basics and Fundamentals","heading":"1.8.2 Random Sampling","text":"sample() function takes sample specified elements x without replacement.Create random sample 20 1 100 replacement:Note, running won’t give output.avoid using set.seed(x) x just arbitrary number","code":"\nsample(1:100, 20, replace = T)##  [1] 41 57 42 61 76  5 29 85 16 74 53  7 35 24 69 95  4 80 87 29\nsample(1:100, 20, replace = T)##  [1] 25 48 67 83 89 37 94 81 13 93 48 71 67 50  2  3 30 13 35 65\nset.seed(415)\nsample(1:100, 20, replace = T)##  [1]  2 94 70 11 91 35 56 47 34 39  1 18 60 29 68  9 70 45 53 67\n# run again\nset.seed(415)\nsample(1:100, 20, replace = T)##  [1]  2 94 70 11 91 35 56 47 34 39  1 18 60 29 68  9 70 45 53 67"},{"path":"r-basics-and-fundamentals.html","id":"repetition","chapter":"1 R Basics and Fundamentals","heading":"1.8.3 Repetition","text":"cases, may just want repeat values. using rep function.OROROR","code":"\n# repeat 1 four times\nrep(x = 1, times = 4)## [1] 1 1 1 1\n# repeat 1 to 5, 10 times\nrep(1:5, times = 10)##  [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3\n## [39] 4 5 1 2 3 4 5 1 2 3 4 5\n# repeat 1, 2, 5, 7, 3 times\nrep(x = c(1, 2, 5, 7), times = 3)##  [1] 1 2 5 7 1 2 5 7 1 2 5 7\n# repeat 1, 2, 5, 7 each values twice\nrep(x = c(1, 2, 5, 7), times = 3, each = 2)##  [1] 1 1 2 2 5 5 7 7 1 1 2 2 5 5 7 7 1 1 2 2 5 5 7 7\n# repeat each element in x by specified vector time (1\n# once, 2 four times, 5, once, and 7 twice)\nrep(x = c(1, 2, 5, 7), times = c(1, 4, 1, 2))## [1] 1 2 2 2 2 5 7 7"},{"path":"conditionals-loops-and-functions.html","id":"conditionals-loops-and-functions","chapter":"2 Conditionals, Loops, and Functions","heading":"2 Conditionals, Loops, and Functions","text":"certain situations, may need control flow logic code. One approach make sections code conditional use loops repeat specific sections multiple times.","code":""},{"path":"conditionals-loops-and-functions.html","id":"if-else-statement","chapter":"2 Conditionals, Loops, and Functions","heading":"2.0.1 If-else statement","text":"","code":"# simple if else\nif (condition) {\n  do if TRUE\n} else {\n  do if FALSE\n}\n\n# extension of if else\nif (condition) {\n  do something\n} else if (condition2) {\n  do something \n} else {\n  do this instead\n}"},{"path":"conditionals-loops-and-functions.html","id":"defining-a-function","chapter":"2 Conditionals, Loops, and Functions","heading":"2.0.2 Defining a Function","text":"","code":"#'\n#' purpose of this function\n#'\n#' @param arg1 define arg1\n#' @param arg2 define arg2\n#'\n#' @return description \nfunction_name <- function(arg1, arg2, ...) {\n  write code here\n  \n  return(returned_object)\n}"},{"path":"conditionals-loops-and-functions.html","id":"recursive-function","chapter":"2 Conditionals, Loops, and Functions","heading":"2.0.3 Recursive Function","text":"recursive function function calls solve smaller instances problem. ’s particularly useful tasks can broken simpler, repetitive sub-tasks,","code":""},{"path":"conditionals-loops-and-functions.html","id":"factorials","chapter":"2 Conditionals, Loops, and Functions","heading":"2.0.3.1 Factorials","text":"example, wanted calculate factorial non-negative integer n,\\[\nn! = n × (n - 1) × (n - 2) × ... × 2 × 1\n\\]Note: R already base function factorial.","code":"\nfactorial_recursive <- function(n) {\n    if (n == 0) {\n        return(1)  # Base case: factorial of 0 is 1\n    } else {\n        return(n * factorial_recursive(n - 1))  # Recursive case\n    }\n}"},{"path":"conditionals-loops-and-functions.html","id":"creating-a-for-loop","chapter":"2 Conditionals, Loops, and Functions","heading":"2.0.4 Creating a for loop","text":"","code":"for (loopindex in vector) {\n  do this\n}"},{"path":"conditionals-loops-and-functions.html","id":"case-study","chapter":"2 Conditionals, Loops, and Functions","heading":"2.0.5 Case Study","text":"’ll start analyzing registered voter data Guam 1990 2020 (taken Guam Statistical Yearbook).1990-2020, mean percent failure vote:Let’s say year percent > 25%, let’s define “poor turnout”, year < 25% failure vote, defined “decent turnout”define function thisTest function value - 4 return “decent” 25 return “poor”.Now, let’s define -Loop use function elements failed_to_vote vector.","code":"\nyear <- seq(from = 2020, to = 1990, by = -2)\nfailed_to_vote <- c(47.4, 33.2, 30.7, 28.1, 32.7, 23.1, 30.9,\n    27.3, 32.9, 26.2, 26.7, 15, 23.7, 14.9, 25.3, 13.5)\n\nnames(failed_to_vote) <- year\nmean(failed_to_vote)## [1] 26.975\n#'\n#' determine if year has 'poor voter turnout' or 'decent voter turnout'\n#'\n#' @param percent numeric percent of failure to vote \n#' \n#' @return string of either 'poor' or 'decent'\ndetermine_outcome <- function(percent) {\n    outcome <- \"\"\n    if (percent >= 25) {\n        outcome <- \"poor\"\n    } else {\n        outcome <- \"decent\"\n    }\n    return(outcome)\n}\nprint(determine_outcome(4))## [1] \"decent\"\nprint(determine_outcome(25))## [1] \"poor\"\n# option 1 for a for loop\n#' this loop iterates over each element in the failed_to_vote vector\n#' we give it an arbitrary name (percent) which represents a single element\n#' of this data vector at a point in our loop\nfor (percent in failed_to_vote) {\n    print(percent)\n    print(determine_outcome(percent))\n}## [1] 47.4\n## [1] \"poor\"\n## [1] 33.2\n## [1] \"poor\"\n## [1] 30.7\n## [1] \"poor\"\n## [1] 28.1\n## [1] \"poor\"\n## [1] 32.7\n## [1] \"poor\"\n## [1] 23.1\n## [1] \"decent\"\n## [1] 30.9\n## [1] \"poor\"\n## [1] 27.3\n## [1] \"poor\"\n## [1] 32.9\n## [1] \"poor\"\n## [1] 26.2\n## [1] \"poor\"\n## [1] 26.7\n## [1] \"poor\"\n## [1] 15\n## [1] \"decent\"\n## [1] 23.7\n## [1] \"decent\"\n## [1] 14.9\n## [1] \"decent\"\n## [1] 25.3\n## [1] \"poor\"\n## [1] 13.5\n## [1] \"decent\"\n# option 2 - index with value\n#' this for loop iterates throught the failed_to_vote vector by specifying their\n#' numeric index. it defines the condition from i in 1:16 (which is the length of the vector)\n#' and for each iteration of the loop, i gets replaced by 1, then by 2, then by 3.. until 16\nfor (i in 1:length(failed_to_vote)) {\n    print(failed_to_vote[i])\n    print(determine_outcome(failed_to_vote[i]))\n}## 2020 \n## 47.4 \n## [1] \"poor\"\n## 2018 \n## 33.2 \n## [1] \"poor\"\n## 2016 \n## 30.7 \n## [1] \"poor\"\n## 2014 \n## 28.1 \n## [1] \"poor\"\n## 2012 \n## 32.7 \n## [1] \"poor\"\n## 2010 \n## 23.1 \n## [1] \"decent\"\n## 2008 \n## 30.9 \n## [1] \"poor\"\n## 2006 \n## 27.3 \n## [1] \"poor\"\n## 2004 \n## 32.9 \n## [1] \"poor\"\n## 2002 \n## 26.2 \n## [1] \"poor\"\n## 2000 \n## 26.7 \n## [1] \"poor\"\n## 1998 \n##   15 \n## [1] \"decent\"\n## 1996 \n## 23.7 \n## [1] \"decent\"\n## 1994 \n## 14.9 \n## [1] \"decent\"\n## 1992 \n## 25.3 \n## [1] \"poor\"\n## 1990 \n## 13.5 \n## [1] \"decent\"\n# save these outcomes\n#' we follow the first option of the for loop, but initialize an outcome variable to store\n#' the value returned by `determine_outcome` into another vector. This variable is\n#' initialized outside of the loop to retain its state or value as the loop runs.\noutcome <- c()\nfor (percent in failed_to_vote) {\n    outcome <- append(outcome, determine_outcome(percent))\n}"},{"path":"conditionals-loops-and-functions.html","id":"lists-vs-vectors","chapter":"2 Conditionals, Loops, and Functions","heading":"2.1 Lists vs Vectors","text":"vector one dimensional array elements. Almost data R stored vector. list recursive vector, meaning list can contain vectors contain vectors lists. Lists can contain lists vectors lists data.frames.","code":""},{"path":"conditionals-loops-and-functions.html","id":"apply-lapply-family","chapter":"2 Conditionals, Loops, and Functions","heading":"2.1.1 apply(), lapply() family","text":"best way loop vector categorize outcome implicit loop. lapply takes vector, list, Dataframe input always returns list. specified function applied element input object.table, let’s grab total percent voted column.can add total_voted failed_to_vote vector list list function.Use functions apply vector:try using, lapply() function determine_outcome, result error due set-function. error appears since determine_outcome expects single numeric value input, passing vector values statement. addition, () statement can check one element vector one time, using code attempted check every element vector .ifelse function allows perform element-wise conditions vectors data frames. (allows vectors traditional ..else ).failed_to_vote vector, many times poor outcomes many times decent outcomes?crude example, specified purpose, just use:However, basic example demonstrating use -loop increment variables.","code":"\noutcomes <- lapply(failed_to_vote, determine_outcome)\n# since the output is always a list we can break it up back\n# into a vector\noutcomes <- unlist(outcomes)\ntotal_voted <- c(52.6, 66.8, 69.3, 71.9, 67.3, 76.9, 69.1, 72.7,\n    67.1, 73.8, 73.3, 85, 76.3, 85.1, 74.7, 86.5)\nnames(total_voted) <- year\nvote_percent <- list(total_voted, failed_to_vote)\nprint(lapply(vote_percent, mean))## [[1]]\n## [1] 73.025\n## \n## [[2]]\n## [1] 26.975\nprint(lapply(vote_percent, summary))## [[1]]\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   52.60   68.65   73.00   73.03   76.45   86.50 \n## \n## [[2]]\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   13.50   23.55   27.00   26.98   31.35   47.40\n# let's fix this by re-defining the function\n\n#'\n#' determine if value indicates 'poor turnout' (>=25) or 'decent turnout' (<25)\n#'\n#' @param percent numeric value that indicates percent of failure to vote\n#'\n#' @return string of either poor or decent\ndetermine_outcome <- function(percent) {\n    ifelse(percent >= 25, \"poor\", \"decent\")\n}\n# define a loop to count this count how many times decent\n# or poor appear\n\n# again, we initialize variables to store our count OUTSIDE\n# of the for loop to retain their value while the loop is\n# running\ndecent_val <- 0\npoor_val <- 0\n\nfor (percent in failed_to_vote) {\n    if (determine_outcome(percent) == \"poor\") {\n        poor_val <- poor_val + 1\n    } else if (determine_outcome(percent) == \"decent\") {\n        decent_val <- decent_val + 1\n    }\n}\ntable(outcomes)## outcomes\n## decent   poor \n##      5     11"},{"path":"introduction-to-dataframes-ggplot2.html","id":"introduction-to-dataframes-ggplot2","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3 Introduction to Dataframes & ggplot2","text":"","code":""},{"path":"introduction-to-dataframes-ggplot2.html","id":"what-is-a-data.frame","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.0.0.1 What is a data.frame?","text":"data.frame R data structure used storing data tabular format. similar spreadsheet, excel sheet, SQL table within R. can also think collection multiple data vectors. ’s two dimensional, meaning rows columns row represents observation column represents variable, attribute, feature.","code":""},{"path":"introduction-to-dataframes-ggplot2.html","id":"what-is-tidyverse","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.0.0.2 What is tidyverse?","text":"introduce concept wrangling, cleaning, transforming dataframes tidyverse package. Tidyverse collection packages help cleaning, transformation, visualization, analysis. (packages Tidyverse include dplyr, ggplot2, tidyr, readr).","code":""},{"path":"introduction-to-dataframes-ggplot2.html","id":"what-is-ggplot2","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.0.0.3 What is ggplot2?","text":"R package data visualization. suite provides easy way visualize data : bar charts, scatter plots, time trends, etc. Writing ggplot code comprises components: data visualized, aesthetics (like variables mapped), geometric objects (shapes represent data).","code":""},{"path":"introduction-to-dataframes-ggplot2.html","id":"case-study-overwatch-2-player-statistics","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.1 Case Study: Overwatch 2 Player Statistics","text":"","code":""},{"path":"introduction-to-dataframes-ggplot2.html","id":"load-inspect-data","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.1.0.1 Load & Inspect Data","text":"Let’s call dataset using read_csv.data loaded R, best first steps take inspect data. can look like lot things plotting variables visualize relationship variables dataset. , main focus get familiar data summarize main characteristics.can also use summary() function ow data.frame provide us summary column.summary() helpful want see range values numeric variables. categorical qualitative variables, like use unique() function show values columns provide.ow data.frame includes Date column, summary() output, categorized character. Let’s re-assign ’s class using .Date function.","code":"\nlibrary(tidyverse)\n# i am defining a string variable with the filepath of the\n# directory that hosts the csv file we are using\ndir <- \"/Users/rdominguez/Documents/MA500/Lessons/datasets/\"\n\n# i use paste0() to concatenate these strings together to\n# provide the full filepath\now <- read_csv(paste0(dir, \"overwatch_stats.csv\"))\n# using the head() function will bring up the first 6 rows\nhead(ow)## # A tibble: 6 × 12\n##   Player  Date     Win Map   Mode  Role  Elimination Assists Deaths Damage Heals\n##   <chr>   <chr>  <dbl> <chr> <chr> <chr>       <dbl>   <dbl>  <dbl>  <dbl> <dbl>\n## 1 player1 8/15/…     1 Sura… Assa… Dama…          28       0      5  11480  2484\n## 2 player1 8/15/…     1 King… Atta… Dama…          17       3      4   6713     0\n## 3 player1 8/15/…     0 New … Robot Tank           27       4      7   5776   122\n## 4 player1 8/15/…     0 Midt… Atta… Dama…           8       3      6   7138     8\n## 5 player1 8/15/…     1 Ilios Atta… Supp…          10       3      4   2163  4849\n## 6 player1 8/15/…     1 Hava… Esco… Tank            7       2      9   4416  2498\n## # ℹ 1 more variable: Mitigation <dbl>\nsummary(ow)##     Player              Date                Win             Map           \n##  Length:87          Length:87          Min.   :0.0000   Length:87         \n##  Class :character   Class :character   1st Qu.:0.0000   Class :character  \n##  Mode  :character   Mode  :character   Median :1.0000   Mode  :character  \n##                                        Mean   :0.6552                     \n##                                        3rd Qu.:1.0000                     \n##                                        Max.   :1.0000                     \n##      Mode               Role            Elimination       Assists      \n##  Length:87          Length:87          Min.   : 4.00   Min.   : 0.000  \n##  Class :character   Class :character   1st Qu.:10.50   1st Qu.: 2.000  \n##  Mode  :character   Mode  :character   Median :15.00   Median : 6.000  \n##                                        Mean   :16.68   Mean   : 8.747  \n##                                        3rd Qu.:21.00   3rd Qu.:12.500  \n##                                        Max.   :58.00   Max.   :51.000  \n##      Deaths           Damage          Heals         Mitigation  \n##  Min.   : 0.000   Min.   :  773   Min.   :    0   Min.   :   0  \n##  1st Qu.: 4.000   1st Qu.: 2974   1st Qu.:  100   1st Qu.:   0  \n##  Median : 6.000   Median : 4336   Median : 1322   Median :   0  \n##  Mean   : 5.989   Mean   : 5166   Mean   : 3214   Mean   :1156  \n##  3rd Qu.: 8.000   3rd Qu.: 6994   3rd Qu.: 5898   3rd Qu.:1798  \n##  Max.   :12.000   Max.   :14824   Max.   :18620   Max.   :7253\n# this will output all unique values in the Player column\nunique(ow$Player)## [1] \"player1\" \"player2\"\n# because the values of Date appear as MM/DD/YY, we use\n# %m/%d/%y to follow the same format %y represents year\n# using 2 digits, where %Y represents year using 4 digits\now$Date <- as.Date(ow$Date, format = \"%m/%d/%y\")"},{"path":"introduction-to-dataframes-ggplot2.html","id":"visualize-data","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.1.0.2 Visualize Data","text":"numeric columns, elimintations, assists, deaths, damage, heals, mitigation.Let’s plot histogram damage column determine distribution values appear .can also create boxplot easily determine potential outliers look like.","code":"\n# hist is a base R function\nhist(ow$Damage)\n# boxplot is also a base R function\nboxplot(ow$Damage)"},{"path":"introduction-to-dataframes-ggplot2.html","id":"data-manipulation","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.1.1 Data Manipulation","text":"Let’s say like compare player’s wins. ’ll compare wins plotting bar chart wins Date. effective straightforward work data long format rather wide. (take look theow dataframe, ’s raw state wide). , let’s make conversion! switch long wide, function pivot_wider, go wide long, use pivot_longer.cols indicates columns want pivot long formatcols indicates columns want pivot long formatnames_to indicates name column saving previous columnsnames_to indicates name column saving previous columnsvalues_to indicates name column saving values corresponding columns colsvalues_to indicates name column saving values corresponding columns colsUse head() function see first 6 rows look like now!Next, want calculate player’s total number wins dataset, summarized date. “Win” column binary, 0 indicating loss 1 indicating win. can simply sum column player get total wins.dplyr, pipe operator, %>%, helps readability action taking data.frame. pipes value left argument follows.","code":"\now <- ow %>%\n    pivot_longer(cols = c(\"Elimination\", \"Assists\", \"Deaths\",\n        \"Damage\", \"Heals\", \"Mitigation\"), names_to = \"Value_Type\",\n        values_to = \"Value\")\n# notice that we now have a column named Value_Type and the\n# values in that column correspond to our previous columns!\nhead(ow)## # A tibble: 6 × 8\n##   Player  Date         Win Map      Mode    Role   Value_Type  Value\n##   <chr>   <date>     <dbl> <chr>    <chr>   <chr>  <chr>       <dbl>\n## 1 player1 2024-08-15     1 Suravasa Assault Damage Elimination    28\n## 2 player1 2024-08-15     1 Suravasa Assault Damage Assists         0\n## 3 player1 2024-08-15     1 Suravasa Assault Damage Deaths          5\n## 4 player1 2024-08-15     1 Suravasa Assault Damage Damage      11480\n## 5 player1 2024-08-15     1 Suravasa Assault Damage Heals        2484\n## 6 player1 2024-08-15     1 Suravasa Assault Damage Mitigation      0\n# we want to group by Player and Date n() is an in house\n# function for tidyverse and simply returns the total\n# within Player and Date\nplayer_wins <- ow %>%\n    group_by(Player, Date) %>%\n    summarise(wins = sum(Win), pct_win = sum(Win)/n() * 100)"},{"path":"introduction-to-dataframes-ggplot2.html","id":"plotting-with-ggplot2","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.1.2 Plotting with ggplot2","text":"","code":""},{"path":"introduction-to-dataframes-ggplot2.html","id":"creating-a-bar-chart","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.1.2.1 Creating a bar chart","text":"","code":"\nbar <- ggplot(data = player_wins, aes(x = Date, y = wins)) +\n    geom_bar(position = \"dodge\", stat = \"identity\", aes(fill = Player))\nprint(bar)"},{"path":"introduction-to-dataframes-ggplot2.html","id":"creating-a-line-graph","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.1.2.2 Creating a line graph","text":"Now, let’s determine number eliminations player based role. achieve , ’ll aggregate wins grouping data Player Role.Let’s create barchart new aggregation.want reorder x-axis chart displays “Tank,” “Damage,” “Support.” Additionally, like reorder facets following order: “Eliminations,” “Assists,” “Deaths,” “Damage,” “Heals,” “Mitigation.” can achieve setting relevant columns factors defining desired levels .Plot chart workSave plot ggsave","code":"\nline <- ggplot(data = player_wins, aes(x = Date, y = pct_win)) +\n    geom_point() + geom_line(aes(color = Player))\nprint(line)\nrole <- ow %>%\n    group_by(Player, Role, Value_Type) %>%\n    summarise(val = sum(Value))\nhead(role)## # A tibble: 6 × 4\n## # Groups:   Player, Role [1]\n##   Player  Role   Value_Type     val\n##   <chr>   <chr>  <chr>        <dbl>\n## 1 player1 Damage Assists         61\n## 2 player1 Damage Damage      139972\n## 3 player1 Damage Deaths         130\n## 4 player1 Damage Elimination    415\n## 5 player1 Damage Heals        14135\n## 6 player1 Damage Mitigation   12348\n# we set facets to create multiple barcharts by Value Type\n# we also set the scales of the y-axis to be free, meaning\n# each barchart will have its own y-axis. we do this\n# because the damage and heal values are way larger than\n# the values for deaths, eliminations, assists, etc.\nchart <- ggplot(data = role, aes(x = Role, y = val)) + geom_bar(position = \"dodge\",\n    stat = \"identity\", aes(fill = Player)) + facet_wrap(~Value_Type,\n    scales = \"free_y\")\nprint(chart)\n# we set the column role to be a factor and define the\n# ordered values with the level argument, we also do the\n# same for the column value type in order to get the facets\n# in our barchart above in the order we would like\nrole$Role <- factor(role$Role, levels = c(\"Tank\", \"Support\",\n    \"Damage\"))\nrole$Value_Type <- factor(role$Value_Type, levels = c(\"Elimination\",\n    \"Assists\", \"Deaths\", \"Damage\", \"Heals\", \"Mitigation\"))\n# plot chart again\nchart <- ggplot(data = role, aes(x = Role, y = val)) + geom_bar(position = \"dodge\",\n    stat = \"identity\", aes(fill = Player)) + facet_wrap(~Value_Type,\n    scales = \"free_y\") + labs(x = \"Role\", y = \"Number\") + theme_minimal()\nprint(chart)\n# saving chart if you don't specify a file path, it will\n# save it working directory\nggsave(filename = \"/Users/rdominguez/Documents/MA500/chart1.png\",\n    plot = chart, dpi = 300)"},{"path":"introduction-to-dataframes-ggplot2.html","id":"merging","chapter":"3 Introduction to Dataframes & ggplot2","heading":"3.2 Merging","text":"Merging data frames process combining two data frames based common columns row indices. common operation data analysis, often need bring together information different sources single data set.Overwatch dataset, ’s accompanying dataset lists heroes played game. know row original Overwatch dataset ’ve working corresponds single game. game’s mechanics, players allowed switch heroes match. result, heroes dataset, ’ll see player may played multiple heroes within game.Let’s read accompanying dataset.can see, hero data frame contains observations Overwatch dataset, 87 entries.use left_join function merge ow data frame hero data frame, match key values hero data ow data. However, first time run , ’ll encounter “many--many relationship” warning. means join occur, generate possible combinations key columns—Player, Date, Win, Map, Mode, Role—various corresponding heroes.simplify things, ’ll join rows associated heroes played game.Another warning, “many--many relationship” warning, appear due duplicates grouped combinations key indicators: Player, Date, Win, Map, Mode, Role. Typically, issue avoided assigning unique identifier game, dataset lacks identifier. Essentially, player can participate multiple games day, even play map role mode. proceed analysis, ’ll need identify duplicate entries remove dataset.ow_with_hero data frame now one row game, one hero per game.Suppose want analyze Player 2’s statistics (number eliminations, assists, heals, damage, deaths, mitigation) hero. , ’ll need filter ow_with_hero data frame include Player 2’s records, aggregate sum Value column get total hero, regardless date.Continue create barchartNow, let’s output .csv file contains player statistics (player) hero. publication easy reading purposes, best show long datasets format wide.First, need summarise hero stats !Pivot long wideHere defining following parameters:id_cols: key columns remain unchanged pivoting, Player, Role, Hero.names_from: Specifies column contains entries want transform column headers converting dataset wide format.names_from: Specifies column contains entries want transform column headers converting dataset wide format.values_from: Specifies column want extract cell values newly created columns.values_from: Specifies column want extract cell values newly created columns.save .csv file, use write_csv function.","code":"\nhero <- read_csv(paste0(dir, \"overwatch_heros.csv\"))\nhero$Date <- as.Date(hero$Date, format = \"%m/%d/%y\")\n# we will first work with filtering the hero data.frame\n# this code groups the hero data.frame by our key (unique\n# idenitifying columns) and takes the higher value from the\n# Percent Played column\n\nhero_most_played <- hero %>%\n    group_by(Player, Date, Win, Map, Mode, Role) %>%\n    filter(`Percent Played` == max(`Percent Played`))\n\n# left join\now_with_hero <- left_join(ow, hero_most_played, by = c(\"Player\",\n    \"Date\", \"Win\", \"Map\", \"Mode\", \"Role\"))## Warning in left_join(ow, hero_most_played, by = c(\"Player\", \"Date\", \"Win\", : Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 139 of `x` matches multiple rows in `y`.\n## ℹ Row 1 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this warning.\n# we will create a new data.frame called duplicate to count\n# the number of instances the grouped key columns appear\nduplicate <- ow_with_hero %>%\n    count(Player, Date, Win, Map, Mode, Role, Value_Type) %>%\n    filter(n > 1) %>%\n    select(-n)\n# now we will use an anti-join to remove these duplicate\n# keys from the overwatch dataset\now_with_hero <- ow_with_hero %>%\n    anti_join(duplicate, by = c(\"Player\", \"Date\", \"Win\", \"Map\",\n        \"Mode\", \"Role\", \"Value_Type\"))\nplayer2 <- ow_with_hero %>%\n    filter(Player == \"player2\") %>%\n    group_by(Player, Role, Hero, Value_Type) %>%\n    summarise(sum_val = sum(Value))\np2 <- ggplot(data = player2, aes(x = Role, y = sum_val)) + geom_bar(position = \"dodge\",\n    stat = \"identity\", aes(fill = Value_Type)) + facet_wrap(~Hero,\n    scales = \"free_y\") + labs(title = \"Player 2 Statistics by Hero\",\n    x = \"Role\", y = \"Number\") + theme_minimal()\n# this is similar to what we did to get player2 stats above\n# but instead we group by hero, if we filter the output of\n# this to just player 2, we should get the same\n# observations as the player2 data.frame\nhero_stats <- ow_with_hero %>%\n    group_by(Player, Role, Hero, Value_Type) %>%\n    summarise(sum_val = sum(Value))\nhero_stats <- pivot_wider(hero_stats, id_cols = c(\"Player\", \"Role\",\n    \"Hero\"), names_from = \"Value_Type\", values_from = \"sum_val\")\n# first argument is the data.frame you are saving second\n# argument is the filepath we would like to save it to\nwrite_csv(hero_stats, paste0(dir, \"ow_hero_stats.csv\"))"},{"path":"data-visualizations.html","id":"data-visualizations","chapter":"4 Data Visualizations","heading":"4 Data Visualizations","text":"Beyond bar charts line graphs discussed previous section, ggplot2 offers variety visualizations can create. ’ll using mtcars dataset, readily available R environment, explore options.","code":"\ndata(mtcars)\nhead(mtcars)##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"},{"path":"data-visualizations.html","id":"types-of-plots","chapter":"4 Data Visualizations","heading":"4.1 Types of Plots","text":"","code":""},{"path":"data-visualizations.html","id":"scatter-plot","chapter":"4 Data Visualizations","heading":"4.1.1 Scatter Plot","text":"Shows relationship two continuous variables","code":"\nscatter <- ggplot(data = mtcars, aes(x = wt, y = mpg)) + geom_point() +\n    labs(x = \"Weight\", y = \"Miles per Gallon\")\nprint(scatter)"},{"path":"data-visualizations.html","id":"line-plot","chapter":"4 Data Visualizations","heading":"4.1.2 Line Plot","text":"Displays trends time ordered data","code":"\nline <- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_line() +\n    labs(x = \"Horsepower\", y = \"Miles Per Gallon\")\nprint(line)\n# if you want to plot the trend of the different values in\n# a categorical variable, you can set it as a color\nline <- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_line(aes(color = factor(gear))) +\n    labs(x = \"Horsepower\", y = \"Miles Per Gallon\", color = \"Number of Gear\")\nprint(line)"},{"path":"data-visualizations.html","id":"bar-plot","chapter":"4 Data Visualizations","heading":"4.1.3 Bar Plot","text":"Displays counts summary statistics categorical data","code":"\nbar <- ggplot(mtcars, aes(x = factor(cyl))) + geom_bar(fill = \"steelblue\") +\n    labs(x = \"Number of Cylinders\", y = \"Count\")\nprint(bar)"},{"path":"data-visualizations.html","id":"histogram","chapter":"4 Data Visualizations","heading":"4.1.4 Histogram","text":"Displays distribution single continuous variable","code":"\nhist <- ggplot(mtcars, aes(x = mpg)) + geom_histogram(binwidth = 2,\n    fill = \"steelblue\") + labs(title = \"Histogram of MPG\", x = \"Miles Per Gallon\",\n    y = \"Frequency\")\nprint(hist)"},{"path":"data-visualizations.html","id":"boxplot","chapter":"4 Data Visualizations","heading":"4.1.5 Boxplot","text":"Displays distribution one multiple continuous variables","code":"\n# you can fill/color the boxes to correspond to a #\n# specific categorical variable as well\nbox <- ggplot(mtcars, aes(x = factor(cyl), y = mpg)) + geom_boxplot(aes(fill = factor(cyl))) +\n    labs(title = \"Box Plot of MPG by Cylinder\", x = \"Number of Cylinders\",\n        y = \"Miles Per Gallon\", fill = \"Number of Cylinders\")\nprint(box)"},{"path":"data-visualizations.html","id":"density-plot","chapter":"4 Data Visualizations","heading":"4.1.6 Density Plot","text":"Displays distribution smoothed curve continuous variable","code":"\ndensity <- ggplot(mtcars, aes(x = mpg)) + geom_density(fill = \"blue\",\n    alpha = 0.5) + labs(x = \"Miles Per Gallon\", y = \"Density\")\nprint(density)"},{"path":"data-visualizations.html","id":"violin-plot","chapter":"4 Data Visualizations","heading":"4.1.7 Violin Plot","text":"show distribution continuous variable categories, combining aspects box plot density plot.","code":"\nviolin <- ggplot(mtcars, aes(x = factor(cyl), y = mpg)) + geom_violin(aes(fill = factor(cyl))) +\n    labs(x = \"Number of Cylinders\", y = \"Miles Per Gallon\", fill = \"Number of Cylinders\")\nprint(violin)"},{"path":"data-visualizations.html","id":"faceted-plots","chapter":"4 Data Visualizations","heading":"4.1.8 Faceted Plots","text":"Creates multiple plots based values categorical variable","code":"\nfacet <- ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point(aes(color = factor(cyl))) +\n    facet_wrap(~cyl) + labs(x = \"Weight\", y = \"Miles Per Gallon (mpg)\",\n    color = \"Number of Cylinders\")\nprint(facet)"},{"path":"data-visualizations.html","id":"themes","chapter":"4 Data Visualizations","heading":"4.2 Themes","text":"ggplot2offers variety built-themes can apply change appearance plots. options can use:theme_grey()theme_grey()theme_bw()theme_bw()theme_linedraw()theme_linedraw()theme_light()theme_light()theme_dark()theme_dark()theme_minimal()theme_minimal()theme_classic()theme_classic()theme_void()theme_void()can implement:","code":"\n# re-using the box plot, we can append a new ggplot element\n# to our variable box\n\nbox <- box + theme_minimal()\nprint(box)"},{"path":"data-visualizations.html","id":"additional-customization","chapter":"4 Data Visualizations","heading":"4.3 Additional Customization","text":"","code":""},{"path":"data-visualizations.html","id":"case-study-airquality-dataset","chapter":"4 Data Visualizations","heading":"4.3.1 Case Study: Airquality Dataset","text":"discuss implement customization visualizations ggplot2, using built-R dataset airquality.summary air dataset shows 6 different variables, 4 continuous 2 representing time. Let’s set labels factor Month column represents named Month instead numeric Month. factor(), can set labels onto levels defining labels, automatically map order current level.creating three distinct plots, encoding ‘Month’ variable use color. visually represent time, ’ll employ gradient blue shades, lighter blues indicating earlier months darker blues representing later months. also ensure 3 plots utilize color gradient.first plot, visualize distribution Temp Month. help us visualize differences temperature month.scale_fill_manual() element ggplot ensures Months colored defined cols vector.scale_fill_manual() element ggplot ensures Months colored defined cols vector.Within theme() element, increasing font size x-axis ticks (axis.text.x), x-axis title (axis.title.x), y-axis ticks (axis.text.y), y-axis title (axis.title.y).Within theme() element, increasing font size x-axis ticks (axis.text.x), x-axis title (axis.title.x), y-axis ticks (axis.text.y), y-axis title (axis.title.y).second plot, visualize temperature trends day. Additionally, ’ll incorporate wind speed another variable. Given wind speed continuous variable, represent varying size data points—smaller points lower wind speeds larger points higher speeds.plot , x defined 1:nrow(air)– column Day air dataset corresponds month, however, since dataset ordered, indices represent true number days.geom_point() element contains argument size defined Wind. ggplot automatically determine breakpoints good split values/sizes .geom_point() element contains argument size defined Wind. ggplot automatically determine breakpoints good split values/sizes .scale_color_manual() function ensures month represented colors discussed previously. , used scale_color_manual instead scale_fill_manual since aesthetic points line color rather fill.scale_color_manual() function ensures month represented colors discussed previously. , used scale_color_manual instead scale_fill_manual since aesthetic points line color rather fill.geom_vline() allows add vertical lines throughout plot provided x-intercept. case, 31,61,92,123, 153 represent indices last days month.geom_vline() allows add vertical lines throughout plot provided x-intercept. case, 31,61,92,123, 153 represent indices last days month.guides(color=\"none\") removes color legend, useful later.guides(color=\"none\") removes color legend, useful later.third plot represent relationship Wind Temp, also including Ozone plot using size represent value. However, plot, also like label datapoints represent max temperature month.Given ’re incorporating Ozone plot, eliminate NAs dataframe. Initially, considered recoding 0, since Ozone column represents average ozone parts per billion, zero value mistakenly indicate actual measurement.Next, going find max temperatures year.geom_text() element enables us annotate plot maximum temperatures. can create dedicated dataset process. supplying max_temp dataframe, exclusively display values contained within dataset.’re interested consolidating plots comprehensive visualization interpretation results, can utilize ggpubr library. tool excellent combining multiple graphics single, cohesive display, making easier compare analyze trends patterns across different datasets.employing ggarrange() function, can arrange ggplot objects single row three columns, specified nrow ncol parameters. ’ve omitted color legends second third plots centralized legends plots bottom achieve streamlined appearance.","code":"\nlibrary(tidyverse)\nair <- airquality\nsummary(air)##      Ozone           Solar.R           Wind             Temp      \n##  Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  \n##  1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  \n##  Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  \n##  Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  \n##  3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  \n##  Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  \n##  NA's   :37       NA's   :7                                       \n##      Month            Day      \n##  Min.   :5.000   Min.   : 1.0  \n##  1st Qu.:6.000   1st Qu.: 8.0  \n##  Median :7.000   Median :16.0  \n##  Mean   :6.993   Mean   :15.8  \n##  3rd Qu.:8.000   3rd Qu.:23.0  \n##  Max.   :9.000   Max.   :31.0  \n## \nair$Month <- factor(air$Month, labels = c(\"May\", \"June\", \"July\",\n    \"August\", \"September\"))\n# create a vector that establishes our colors for each\n# month\nmonths <- c(\"May\", \"June\", \"July\", \"August\", \"September\")\ncols <- c(\"#CAF0F8\", \"#90E0EF\", \"#00B4D8\", \"#0077B6\", \"#03045E\")\n\nnames(cols) <- months\ng1 <- ggplot(data = air, aes(x = Temp, fill = Month)) + geom_density(alpha = 0.7) +\n    scale_fill_manual(name = \"Months\", values = cols) + theme(axis.text.x = element_text(size = 14),\n    axis.text.y = element_text(size = 14), axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20))\nprint(g1)\ng2 <- ggplot(data = air, aes(x = 1:nrow(air), y = Temp)) + geom_line(aes(col = Month)) +\n    geom_point(aes(col = Month, size = Wind)) + geom_smooth(method = \"loess\",\n    col = \"black\") + scale_color_manual(name = \"Months\", values = cols) +\n    geom_vline(xintercept = c(31, 61, 92, 123, 153), linetype = \"dashed\") +\n    guides(color = \"none\") + labs(x = \"Day\")\nprint(g2)\nair_remove <- air %>%\n    filter(Ozone != (is.na(Ozone)))\nmax_temp <- air %>%\n    group_by(Month) %>%\n    filter(Temp == max(Temp))\ng3 <- ggplot(data = air, aes(x = Wind, y = Temp)) + geom_point(aes(size = Ozone,\n    color = Month)) + geom_smooth(method = \"lm\", alpha = 0.2,\n    aes(color = Month)) + geom_text(data = max_temp, aes(label = Temp),\n    vjust = -1, hjust = 0.5) + scale_color_manual(name = \"Months\",\n    values = cols) + guides(color = \"none\")\nprint(g3)## Warning: Removed 37 rows containing missing values (`geom_point()`).\nlibrary(ggpubr)\ncombined_plot <- ggarrange(g1, g2, g3, nrow = 1, ncol = 3, legend = \"bottom\")## Warning: Removed 37 rows containing missing values (`geom_point()`).\nprint(combined_plot)"},{"path":"statistics.html","id":"statistics","chapter":"5 Statistics","heading":"5 Statistics","text":", go basic concepts analyzing univariate bivariate data. using built-R dataset mtcars, can call right away console (typing mtcars).help page bring description, columns definitions, etc. , know data comes 1974 Motor Trend US magazine variables pertaining miles per gallon, number cylinders, etc.","code":"\n`?`(mtcars  # this brings up the documentation on the dataset\n)"},{"path":"statistics.html","id":"measures-of-central-tendency","chapter":"5 Statistics","heading":"5.1 Measures of Central Tendency","text":"","code":""},{"path":"statistics.html","id":"mean-median-mode","chapter":"5 Statistics","heading":"5.1.1 Mean, Median, Mode","text":"mean, median, mode dataset helps identify central typical value data. R built functions find mean median, mode.find values frequent , can use table() functionUsing table() manageable data small, efficient define function output largest value.","code":"\nmean(mtcars$wt)## [1] 3.21725\nmedian(mtcars$wt)## [1] 3.325\n# this shows the number of observations for every unique\n# value of cyl\ntable(mtcars$cyl)## \n##  4  6  8 \n## 11  7 14\n# this function extends the functionality of table, but\n# sorts it so that when we pull the first element, we get\n# the largest value\nmode <- function(x) {\n    names(sort(-table(x)))[1]\n}\nmode(mtcars$cyl)## [1] \"8\""},{"path":"statistics.html","id":"min-max-range","chapter":"5 Statistics","heading":"5.1.2 Min, Max, Range","text":"useful functions: min(), max(), range(), diff().","code":"\nmin(mtcars$wt)## [1] 1.513\nmax(mtcars$wt)## [1] 5.424\nrange(mtcars$wt)  # this provides both min and max## [1] 1.513 5.424\ndiff(range(mtcars$wt))## [1] 3.911"},{"path":"statistics.html","id":"summary-by-factors","chapter":"5 Statistics","heading":"5.1.3 Summary by factors","text":"Let’s say want find mean cars grouped gears, can write loop can use another implicit loop called tapply - helps calculate summary statistics different factors.code can translated :can also use tapply statistical summary functions, even include mode function (takes user-defined functions well!)","code":"\nmean(mtcars$wt[mtcars$gear == 3])## [1] 3.8926\nmean(mtcars$wt[mtcars$gear == 4])## [1] 2.616667\nmean(mtcars$wt[mtcars$gear == 5])## [1] 2.6326\ntapply(mtcars$wt, INDEX = mtcars$gear, FUN = mean)##        3        4        5 \n## 3.892600 2.616667 2.632600\ntapply(mtcars$wt, INDEX = mtcars$gear, FUN = median)##    3    4    5 \n## 3.73 2.70 2.77\ntapply(mtcars$wt, INDEX = mtcars$gear, FUN = min)##     3     4     5 \n## 2.465 1.615 1.513\ntapply(mtcars$wt, INDEX = mtcars$gear, FUN = max)##     3     4     5 \n## 5.424 3.440 3.570\ntapply(mtcars$wt, INDEX = mtcars$gear, FUN = mode)##       3       4       5 \n## \"2.465\"  \"3.44\" \"1.513\""},{"path":"statistics.html","id":"weighted-averages","chapter":"5 Statistics","heading":"5.1.4 Weighted Averages","text":"case values weighted (valued importance) believe affect mean data, calculate weighted average. , let’s create data.frame represents scores student class received respective weights.","code":"\n# Sample data: students' grades and corresponding weights\n# for each assignment\ngrades <- c(85, 92, 78, 88, 90)  # Grades received on different assignments\nweights <- c(0.2, 0.3, 0.1, 0.25, 0.15)  # Weights of each assignment\n\n# Calculate the weighted average\nweighted_average <- sum(grades * weights)\n\n# Print the result\ncat(\"The weighted average grade is:\", weighted_average, \"\\n\")## The weighted average grade is: 87.9\n# OR (from the stats library)\nweighted.mean(grades, weights)## [1] 87.9"},{"path":"statistics.html","id":"quantiles-and-percentiles","chapter":"5 Statistics","heading":"5.2 Quantiles and Percentiles","text":"quantile (divides 4 equal parts)/percentile (divides 100 equal parts) value computed collection numeric measurements indicates observation’s rank.can also run 5 number summary:","code":"\nquantile(mtcars$mpg, prob = 0.8)  # this outputs the 80th percentile##   80% \n## 24.08\nquantile(mtcars$mpg, prob = c(0, 0.25, 0.5, 0.75, 1))##     0%    25%    50%    75%   100% \n## 10.400 15.425 19.200 22.800 33.900\nsummary(mtcars$mpg)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   10.40   15.43   19.20   20.09   22.80   33.90"},{"path":"statistics.html","id":"measures-of-spread","chapter":"5 Statistics","heading":"5.3 Measures of Spread","text":"Measures spread helpful want see dispersed data .sample variance sample standard deviation can computed var() sd() function.interquartile range can given IQR()","code":"\nvar(mtcars$mpg)## [1] 36.3241\nsd(mtcars$mpg)## [1] 6.026948\nIQR(mtcars$mpg)## [1] 7.375"},{"path":"statistics.html","id":"analysis-of-bi-variate-data","chapter":"5 Statistics","heading":"5.4 Analysis of Bi-Variate Data","text":"","code":""},{"path":"statistics.html","id":"correlation-and-covariance","chapter":"5 Statistics","heading":"5.4.1 Correlation and Covariance","text":"useful able investigate relationship two numeric variables assess trends. instance, can hypothesize height weight may relationship taller people tend weigh .Covariance expresses much two numeric variables change together (whether positive negative)\npositive result indicates positive linear relationship - x increases, y increases\nnegative result indicates negative linear relationship - x decreases, y decreases\nresult 0, linear relationship.\npositive result indicates positive linear relationship - x increases, y increasesa negative result indicates negative linear relationship - x decreases, y decreaseswhen result 0, linear relationship.Correlation helps interpret covariance assessing strength direction. Pearson’s correlation coefficient \\(\\rho_{xy}\\)} commonly used measure, \\(-1 \\leq \\rho_{xy} \\leq 1\\)\n\\(\\rho_{xy} = -1\\), indicates near perfect negative linear relationship\n\\(\\rho_{xy} = 1\\), indicates near perfect positive linear relationship\nrelationship gets weaker closer coefficient 0.\n\\(\\rho_{xy} = -1\\), indicates near perfect negative linear relationship\\(\\rho_{xy} = 1\\), indicates near perfect positive linear relationshipthe relationship gets weaker closer coefficient 0.","code":""},{"path":"statistics.html","id":"case-study-mtcars","chapter":"5 Statistics","heading":"5.4.1.1 Case-Study: mtcars","text":"Let’s investigate mtcars dataset see relationship hp qsec, shortest time taken travel quarter-mile distance. Continue plot scatter compute covariance correlation coefficient.Now, let’s look transmission (manual vs auto) cars. Based documentation, 0 = automatic 1 = manual let’s recode new variable. ’ll go ahead plot mtcars$hp mtcars$qsec transmission.Based scatter, can see automatic manual cars, relationship horsepower time gets quarter mile still possesses negative relationship. Let’s find correlation coefficient automatic manual cars.interested looking variable’s correlation eachother, can runFor simplier usage, can use functions corrplot library.","code":"\nscatter <- ggplot(data = mtcars, aes(x = hp, y = qsec)) + geom_point()\nprint(scatter)\ncov(mtcars$hp, mtcars$qsec)## [1] -86.77008\ncor(mtcars$hp, mtcars$qsec)## [1] -0.7082234\nmtcars <- mtcars %>%\n    mutate(tranfac = ifelse(am == 1, \"manual\", \"automatic\"))\nscatter <- ggplot(data = mtcars, aes(x = hp, y = qsec)) + geom_point() +\n    facet_wrap(~tranfac)\nprint(scatter)\n# automatic\ncor(mtcars$hp[mtcars$am == 0], mtcars$qsec[mtcars$am == 0])## [1] -0.8040275\n# manual\ncor(mtcars$hp[mtcars$am == 1], mtcars$qsec[mtcars$am == 1])## [1] -0.8494566\n# we have to remove the tranfac column since it is not\n# numeric\nmtcars <- mtcars %>%\n    select(-tranfac)\n# the cor function provides a correlation matrix\ncor_matrix <- round(cor(mtcars), 2)\n\n# saving it to a data.frame to allow plotting in ggplot2\ncor_matrix <- as.data.frame(cor_matrix)\ncor_matrix$var1 <- row.names(cor_matrix)\ncor_matrix <- pivot_longer(cor_matrix, cols = colnames(mtcars),\n    names_to = \"var2\")\ncor_matrix$var1 <- factor(cor_matrix$var1, levels = colnames(mtcars))\ncor_matrix$var2 <- factor(cor_matrix$var2, levels = colnames(mtcars))\n# create a correlation matrix heatmap\nheatmap <- ggplot(cor_matrix, aes(x = var1, y = var2, fill = value)) +\n    geom_tile()\nprint(heatmap)\nlibrary(corrplot)## Warning: package 'corrplot' was built under R version 4.3.3\ncor_matrix <- round(cor(mtcars), 2)\ncorrplot(cor_matrix)\ncorrplot(cor_matrix, method = \"square\", type = \"lower\", order = \"FPC\")"},{"path":"probability.html","id":"probability","chapter":"6 Probability","heading":"6 Probability","text":", going discuss R functionality probability (base R functions stats).distribution core R functions- d function, providing specific mass density function values - p function, providing cumulative distribution probability - q function, providing quantiles- r function, providing random variate generation","code":""},{"path":"probability.html","id":"binomial-distribution","chapter":"6 Probability","heading":"6.1 Binomial Distribution","text":"binomial distribution distribution successes within n trials involving discrete random variables.\\[f(x) = P_r(X=x) = \\binom{n}{x}p^x(1-p)^{n-x}\\]\\(x \\{0,1,...n}\\). parameters \\(X \\sim BIN(n,p)\\) used indicate X follows binomial distribution \\(n\\) trials probability \\(p\\).Let’s say want roll die success measure 4 rolled. know probability getting 4 \\(P(\\text{roll 4}) = \\frac{1}{6}\\). Let’s say want roll die 8 times.probability 8 times, get exactly 5 successes (roll 4 5 times)?\nfunction dbinom directly provides mass function probability valid \\(x\\).\nprobability 8 times, get exactly 5 successes (roll 4 5 times)?function dbinom directly provides mass function probability valid \\(x\\).can also provide vector x interested full probability mass function table X.Let’s plot PMF!achievement ONE success eight trials highest probability.Using pbinom provide cumulative probability distribution. Let’s say want find \\(\\text{Pr}(X \\leq 5)\\)rbinom function randomly generate realizations (value actually observed something happen) binomally distributed variable. N refers number realizations observations like. example, realization refers number successes running 8 trials.","code":"\ndbinom(x = 5, size = 8, prob = 1/6)  # size is the number of trials## [1] 0.004167619\nX.prob <- dbinom(x = 0:8, size = 8, prob = 1/6)\nprint(round(X.prob, 3))## [1] 0.233 0.372 0.260 0.104 0.026 0.004 0.000 0.000 0.000\n# verify that it equals 1\nsum(X.prob)## [1] 1\n# we set X to be all possible outcomes (how many successes\n# we can have in 8 trials)\nX <- 0:8\n\n# create a data.frame to input into ggplot\ndf <- data.frame(X = X, prob = X.prob)\n\nbar <- ggplot(data = df, aes(x = factor(X), y = prob)) + geom_bar(stat = \"identity\") +\n    labs(x = \"x\", y = \"Pr(X=X)\") + theme_minimal()\npbinom(q = 5, size = 8, prob = 1/6)## [1] 0.9995588\n# can verify that it works the same way with the sum of\n# dbinom from 0 to 5\nsum(dbinom(x = 0:5, size = 8, prob = 1/6))## [1] 0.9995588\nrbinom(n = 1, size = 8, prob = 1/6)## [1] 0\nrbinom(n = 3, size = 8, prob = 1/6)## [1] 1 1 2"},{"path":"probability.html","id":"normal-distribution","chapter":"6 Probability","heading":"6.2 Normal Distribution","text":"normal Gaussian distribution probability distribution symmetric mean. (Data frequent occurance closer mean mean).continuous random variable, \\(- \\infty < X < \\infty\\)\\[f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\text{exp} \\left\\{ - \\frac{(x-\\mu)^2}{2\\sigma^2}\\right\\}\\]notation \\(X \\sim N(\\mu, \\sigma)\\) used indicate “X follows normal distribution mean \\(\\mu\\) standard deviation \\(\\sigma\\).can use dnorm function find value \\(f(x)\\) \\(x\\). Let’s simulate datapoints.pnorm function provides value cumulative density function normal distribution.Ex: length time taken complete certain statistics question first-year undergraduate students average 17 minutes standard deviation 4.5 minutes (\\(X\\) normally distributed.)probability randomly selected undergraduate takes 20 minutes complete question?probability student takes 5-10 minutes finish question?q function, qnorm provides quantile value give lower-tailed probability. Think inverse pnorm.Let’s plot \\(N \\sim (17, 4.5)\\)rnorm function produces random variates given normal distribution. Let’s simulate amount time students take finish statistical question plot distribution histogram.histogram shows simulated values follow normal distribution! , let’s continue validating normality data plotting QQ (quantile-quantile) plot. plot calculates range sample quantile values observed data plots quantiles correspondingly standardized normal distribution. built-function qqnrom help us achieve ! Theoretically, values fall well within 45 degree reference line normally distributed since comparing standard normal distribution plot, normal, values deviate 45 degree line.","code":"\nvals <- seq(-3, 3, length = 200)\nfx <- dnorm(vals, mean = 0, sd = 1)\nprint(fx[0:10])##  [1] 0.004431848 0.004849204 0.005301041 0.005789713 0.006317688 0.006887545\n##  [7] 0.007501981 0.008163805 0.008875944 0.009641434\n1 - pnorm(20, mean = 17, 4.5)  # we subtract from 1 since pnorm provides left-tailed probabilities## [1] 0.2524925\npnorm(10, 17, 4.5) - pnorm(5, 17, 4.5)## [1] 0.05607653\npnorm(10, 17, 4.5)## [1] 0.05990691\nqnorm(pnorm(10, 17, 4.5), mean = 17, sd = 4.5)  # this outputs 10 ## [1] 10\nvals <- seq(17 - 4 * 4.5, 17 + 4 * 4.5, length.out = 500)  # create a sequence of values with +/- 4 standard deviations\nfx <- dnorm(vals, mean = 17, sd = 4.5)\n\n# save to a data.frame to input into ggplot\ndf <- data.frame(x = vals, y = fx)\n\nnormal <- ggplot(data = df, aes(x = x, y = y)) + geom_polygon(fill = \"blue\",\n    alpha = 0.4) + geom_vline(xintercept = 17, linetype = \"dashed\") +\n    theme_minimal() + labs(title = \"N ~ (17, 4.5)\")\n\nprint(normal)\nsim <- rnorm(n = 200, mean = 17, sd = 4.5)\nhist(sim)\nqqnorm(sim, main = \"Normal QQ plot of generated N(17,4.5)\")\nqqline(sim, col = \"gray\")"},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"7 Hypothesis Testing","heading":"7 Hypothesis Testing","text":"Today, going go concepts Hypothesis Testing, specifically Student’s t-test Analysis Variance (ANOVA).","code":""},{"path":"hypothesis-testing.html","id":"assumptions-of-t-test","chapter":"7 Hypothesis Testing","heading":"7.0.0.1 Assumptions of T-Test","text":"Independence ObservationsIndependence ObservationsNormality Dependent VariableNormality Dependent VariableEqual Variances (Homogeneity Variance)Equal Variances (Homogeneity Variance)","code":""},{"path":"hypothesis-testing.html","id":"assumptions-of-anova","chapter":"7 Hypothesis Testing","heading":"7.0.0.2 Assumptions of ANOVA","text":"Independence ObservationsIndependence ObservationsNormality Dependent VariableNormality Dependent VariableEqual Variances (Homogeneity Variance)Equal Variances (Homogeneity Variance)using mock_outplanting_data.csv file available Moodle. dataset contains simulated height measurements (centimeters) three different plant species native Guam, collected two separate dates. Please note height values simulated maintain data privacy.take look summary, see minimum value Height -11.23. know height positive, let’s move forward believing error data inputting remove analysis.bit data cleaning dataset. look unique values Species, notice multiple typos/spelling errors species. want make sure correct move forward analysis.fix errors using grepl function. grepl() R function used pattern matching within strings. checks whether specific pattern (regular expression) exists element character vector, returns logical vector (TRUE FALSE) indicating whether pattern found element.code searches value Species column matches specified pattern, Pan Pandanus tectorius, Pre Premna serratifolia, Ix Ixora triantha, overwrites values match pattern correct spelling like.","code":"\n# load in packages needed\nlibrary(tidyverse)\nlibrary(stats)\nlibrary(psych)## Warning: package 'psych' was built under R version 4.3.3\ndf <- read_csv(\"/Users/rdominguez/MA500/mock_outplanting_data.csv\")\n\n# familarize with the data\nhead(df)## # A tibble: 6 × 4\n##   id    Date    Species             Height\n##   <chr> <chr>   <chr>                <dbl>\n## 1 Pa1   2020-04 Pandanus tectorius    40.4\n## 2 Pr1   2020-04 Premna.serratifolia   28.2\n## 3 Ix1   2020-04 Ixora.triantha        18.2\n## 4 Pa2   2020-04 Pandanus tectorius    31.5\n## 5 Pr2   2020-04 Premna.serratifolia   38.8\n## 6 Ix2   2020-04 Ixora.triantha        20.1\nsummary(df)##       id                Date             Species              Height      \n##  Length:300         Length:300         Length:300         Min.   :-11.23  \n##  Class :character   Class :character   Class :character   1st Qu.: 27.06  \n##  Mode  :character   Mode  :character   Mode  :character   Median : 38.86  \n##                                                           Mean   : 61.18  \n##                                                           3rd Qu.:100.71  \n##                                                           Max.   :198.56\ndf <- df %>%\n    filter(Height > 0)\n# recoding Pandanus\nunique(df$Species[grepl(\"Pan\", df$Species)])## [1] \"Pandanus tectorius\" \"Pandanus.tectorius\" \"Pandaus tectorius\"\ndf$Species[grepl(\"Pan\", df$Species)] <- \"Pandanus tectorius\"\n\n\n# recoding Premna\nunique(df$Species[grepl(\"Pre\", df$Species)])## [1] \"Premna.serratifolia\" \"Premna serratifolia\" \"Prenna serratifolia\"\n## [4] \"Premma Serratifolia\" \"Premma serratifolia\"\ndf$Species[grepl(\"Pre\", df$Species)] <- \"Premna serratifolia\"\n\n# recoding Ixora\ndf$Species[grepl(\"Ix\", df$Species)] <- \"Ixora triantha\""},{"path":"hypothesis-testing.html","id":"visualizing-datadiagnostics","chapter":"7 Hypothesis Testing","heading":"7.1 Visualizing Data/Diagnostics","text":"proceeding hypothesis testing assessing statistical significance, ’s important first ensure data meets assumptions required tests plan use. assumptions met, may need explore alternative approaches adjustments address issue.diagnostics primarily involve examining distribution data within groups intend test. includes generating density plots histograms, creating QQ plots, constructing box plots. visual tools provide valuable insights overall characteristics distribution data.","code":"\n# we are subsetting to just the first date given in our\n# dataset\nunique(df$Date)## [1] \"2020-04\" \"2021-09\"\ndf_day1 <- df %>%\n    dplyr::filter(Date == \"2020-04\")"},{"path":"hypothesis-testing.html","id":"creating-a-density-plot","chapter":"7 Hypothesis Testing","heading":"7.1.1 Creating a Density Plot","text":"density plot, can compare means group visually. observation, can see Pandanus tectorius wider spread data (meaning higher variance value) means Ixora triantha Premna serratifolia differ. distribution separately (species) however look follow normal distribution.","code":"\n# normality diagnostics\ndens <- ggplot(data = df_day1, aes(x = Height)) + geom_histogram(aes(y = after_stat(density)),\n    binwidth = 2, color = \"black\", fill = \"white\") + geom_density(aes(color = Species,\n    fill = Species), alpha = 0.6)\n\nprint(dens)"},{"path":"hypothesis-testing.html","id":"creating-a-qq-plot-for-each-group","chapter":"7 Hypothesis Testing","heading":"7.1.2 Creating a QQ plot for each group","text":"Creating qqplot also reinforces data looks normal!","code":"\nqqnorm(df_day1$Height[df_day1$Species == \"Ixora triantha\"])\nqqline(df_day1$Height[df_day1$Species == \"Ixora triantha\"], col = \"gray\")\nqqnorm(df_day1$Height[df_day1$Species == \"Pandanus tectorius\"])\nqqline(df_day1$Height[df_day1$Species == \"Pandanus tectorius\"],\n    col = \"gray\")\nqqnorm(df_day1$Height[df_day1$Species == \"Premna serratifolia\"])\nqqline(df_day1$Height[df_day1$Species == \"Premna serratifolia\"],\n    col = \"gray\")"},{"path":"hypothesis-testing.html","id":"creating-a-boxplot-for-each-group","chapter":"7 Hypothesis Testing","heading":"7.1.3 Creating a boxplot for each group","text":"","code":"\nbp <- ggplot(data = df_day1, aes(x = Species, y = Height)) +\n    geom_boxplot(aes(fill = Species))\nprint(bp)\ndescribeBy(df_day1, group = df_day1$Species)## \n##  Descriptive statistics by group \n## group: Ixora triantha\n##         vars  n  mean    sd median trimmed   mad   min   max range skew\n## id         1 50 25.50 14.58  25.50    25.5 18.53  1.00 50.00  49.0 0.00\n## Date       2 50  1.00  0.00   1.00     1.0  0.00  1.00  1.00   0.0  NaN\n## Species    3 50  1.00  0.00   1.00     1.0  0.00  1.00  1.00   0.0  NaN\n## Height     4 50 21.31  6.30  19.88    21.1  6.79 10.16 35.66  25.5 0.31\n##         kurtosis   se\n## id         -1.27 2.06\n## Date         NaN 0.00\n## Species      NaN 0.00\n## Height     -0.76 0.89\n## ------------------------------------------------------------ \n## group: Pandanus tectorius\n##         vars  n  mean    sd median trimmed   mad   min    max range  skew\n## id         1 50 75.50 14.58  75.50   75.50 18.53 51.00 100.00 49.00  0.00\n## Date       2 50  1.00  0.00   1.00    1.00  0.00  1.00   1.00  0.00   NaN\n## Species    3 50  2.00  0.00   2.00    2.00  0.00  2.00   2.00  0.00   NaN\n## Height     4 50 42.24 12.50  41.15   42.32 12.33  6.24  71.46 65.22 -0.18\n##         kurtosis   se\n## id         -1.27 2.06\n## Date         NaN 0.00\n## Species      NaN 0.00\n## Height      0.32 1.77\n## ------------------------------------------------------------ \n## group: Premna serratifolia\n##         vars  n   mean    sd median trimmed   mad min    max range  skew\n## id         1 50 125.50 14.58  125.5   125.5 18.53 101 150.00 49.00  0.00\n## Date       2 50   1.00  0.00    1.0     1.0  0.00   1   1.00  0.00   NaN\n## Species    3 50   3.00  0.00    3.0     3.0  0.00   3   3.00  0.00   NaN\n## Height     4 50  31.96  7.30   32.2    32.2  5.98  12  45.38 33.39 -0.33\n##         kurtosis   se\n## id         -1.27 2.06\n## Date         NaN 0.00\n## Species      NaN 0.00\n## Height     -0.09 1.03"},{"path":"hypothesis-testing.html","id":"running-two-sample-t-test","chapter":"7 Hypothesis Testing","heading":"7.2 Running two-sample t-test","text":"Let’s test means heights Pandanus tectorius Ixora triantha different, ie\\[\nH_0: \\mu_{1} - \\mu_{2} = 0 \\\\\nH_A: \\mu_{1} - \\mu_{2} \\neq 0\n\\]test means Pandanus tectorius greater Ixora triantha, ie\\[\nH_0: \\mu_1 - \\mu_2 = 0 \\\\\nH_A: \\mu_1 - \\mu_2 >0\n\\]Based results , can reject null hypotheses say exist difference mean heights Pandanus tectorius Ixora triantha (p < 2.547e-16) mean height Pandanus tectorius greater mean height Ixora triantha (p < 2.2e-16).BIG NOTE: ran two-sample t-test comparing mean height Ixora triantha Premna serratifolia, can run standard two-sample t-test due variances approximately equal (another way check : ratio (var(group1)/var(group2) < 2).","code":"\ntwo_samp <- df_day1 %>%\n    dplyr::filter(Species != \"Premna serratifolia\")\nunique(two_samp$Species)## [1] \"Pandanus tectorius\" \"Ixora triantha\"\nt.test(Height ~ Species, data = two_samp)## \n##  Welch Two Sample t-test\n## \n## data:  Height by Species\n## t = -10.567, df = 72.407, p-value = 2.547e-16\n## alternative hypothesis: true difference in means between group Ixora triantha and group Pandanus tectorius is not equal to 0\n## 95 percent confidence interval:\n##  -24.87278 -16.97826\n## sample estimates:\n##     mean in group Ixora triantha mean in group Pandanus tectorius \n##                         21.31458                         42.24010\n# is ixora mean > pandanus mean?\nt.test(Height ~ Species, data = two_samp, alternative = \"greater\")## \n##  Welch Two Sample t-test\n## \n## data:  Height by Species\n## t = -10.567, df = 72.407, p-value = 1\n## alternative hypothesis: true difference in means between group Ixora triantha and group Pandanus tectorius is greater than 0\n## 95 percent confidence interval:\n##  -24.22502       Inf\n## sample estimates:\n##     mean in group Ixora triantha mean in group Pandanus tectorius \n##                         21.31458                         42.24010\n# is ixora mean < pandanus mean?\nt.test(Height ~ Species, data = two_samp, alternative = \"less\")## \n##  Welch Two Sample t-test\n## \n## data:  Height by Species\n## t = -10.567, df = 72.407, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group Ixora triantha and group Pandanus tectorius is less than 0\n## 95 percent confidence interval:\n##       -Inf -17.62601\n## sample estimates:\n##     mean in group Ixora triantha mean in group Pandanus tectorius \n##                         21.31458                         42.24010\nt.test(x = two_samp$Height[two_samp$Species == \"Pandanus tectorius\"],\n    y = two_samp$Height[two_samp$Species == \"Ixora triantha\"],\n    alternative = \"greater\")## \n##  Welch Two Sample t-test\n## \n## data:  two_samp$Height[two_samp$Species == \"Pandanus tectorius\"] and two_samp$Height[two_samp$Species == \"Ixora triantha\"]\n## t = 10.567, df = 72.407, p-value < 2.2e-16\n## alternative hypothesis: true difference in means is greater than 0\n## 95 percent confidence interval:\n##  17.62601      Inf\n## sample estimates:\n## mean of x mean of y \n##  42.24010  21.31458"},{"path":"hypothesis-testing.html","id":"running-a-paired-t-test","chapter":"7 Hypothesis Testing","heading":"7.3 Running a paired t-test","text":"section, test difference means heights Premna serratifolia two recorded dates, ie\\[\nH_0: \\mu_d = 0 \\\\\nH_A: \\mu_d \\neq 0\n\\]Let’s move forward pivot dataset can see heights date side--side. help visually see specific plant (uniquely identified id) changes two dates.t-test results show p-value less 0.05, meaning can reject null hypothesis mean difference heights first recorded day last recorded day 0.","code":"\nprem <- df %>%\n    dplyr::filter(Species == \"Premna serratifolia\")\nprem_dens <- ggplot(data = prem, aes(x = Height)) + geom_histogram(aes(y = after_stat(density)),\n    binwidth = 2, color = \"black\", fill = \"white\") + geom_density(aes(color = Date,\n    fill = Date), alpha = 0.5) + theme_minimal()\nprint(prem_dens)\nqqnorm(prem$Height[prem$Date == \"2020-04\"])\nqqnorm(prem$Height[prem$Date == \"2021-09\"])\nprem_wide <- pivot_wider(data = prem, id_cols = \"id\", names_from = \"Date\",\n    values_from = \"Height\")\nprem_wide <- prem_wide %>%\n    mutate(diff = `2021-09` - `2020-04`)\nprem_wide <- prem_wide %>%\n    rename(before = `2020-04`) %>%\n    rename(after = `2021-09`)\nhead(prem_wide)## # A tibble: 6 × 4\n##   id    before after  diff\n##   <chr>  <dbl> <dbl> <dbl>\n## 1 Pr1     28.2 125.   96.3\n## 2 Pr2     38.8 120.   80.7\n## 3 Pr3     38.9  72.0  33.0\n## 4 Pr4     12.0 118.  106. \n## 5 Pr5     29.4  68.0  38.6\n## 6 Pr6     27.4 157.  129.\n# running a paired t-test, make sure the paired argument is\n# TRUE\nt.test(x = prem_wide$after, y = prem_wide$before, paired = TRUE)## \n##  Paired t-test\n## \n## data:  prem_wide$after and prem_wide$before\n## t = 21.319, df = 49, p-value < 2.2e-16\n## alternative hypothesis: true mean difference is not equal to 0\n## 95 percent confidence interval:\n##   88.4927 106.9122\n## sample estimates:\n## mean difference \n##        97.70243"},{"path":"hypothesis-testing.html","id":"one-way-anova","chapter":"7 Hypothesis Testing","heading":"7.4 One-way ANOVA","text":"ANOVA, going test difference mean heights species.\\[\nH_0: \\mu_1 = \\mu_2 = \\mu_3 \\\\\nH_A: \\text{means equal (least one mean different)}\n\\]data, going run test first date height recorded.Since anova tells us least one groups difference means, can perform post-hoc test determine groups exactly different. common one Tukey Honest Significant Differences test.","code":"\nanova <- aov(Height ~ Species, data = df_day1)\nsummary(anova)##              Df Sum Sq Mean Sq F value Pr(>F)    \n## Species       2  10948    5474   65.86 <2e-16 ***\n## Residuals   147  12218      83                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nTukeyHSD(anova)##   Tukey multiple comparisons of means\n##     95% family-wise confidence level\n## \n## Fit: aov(formula = Height ~ Species, data = df_day1)\n## \n## $Species\n##                                             diff        lwr       upr p adj\n## Pandanus tectorius-Ixora triantha       20.92552  16.608378 25.242659 0e+00\n## Premna serratifolia-Ixora triantha      10.64516   6.328021 14.962303 1e-07\n## Premna serratifolia-Pandanus tectorius -10.28036 -14.597497 -5.963216 3e-07"},{"path":"case-study-wine-quality-dataset.html","id":"case-study-wine-quality-dataset","chapter":"Case Study: Wine Quality Dataset","heading":"Case Study: Wine Quality Dataset","text":"Wine Quality dataset comes UCI Machine Learning Repository. contains information chemical properties red white variants Portuguese wines, well quality rating. can read : Wine QualityNote: manipulating data data.table notation rather using dplyr.addition summary, getting statistical measures can done describe describeBy functions pysch package.Visualize data:Another way view correlation scatter points together using library(GGally):Discuss:Visualize distribution “free sulfur dioxide” variable, grouped wine color. Perform t-test determine significant difference mean free sulfur dioxide red white wines. Next, rerun t-test removing free sulfur dioxide values greater 100. Record number observations dropped. Finally, run analysis removing potential outliers , record number observations dropped. results differ across steps?Based plots , can observe mean values free sulfur dioxide red white wines visually different. Let’s run t-test see statistically significant.Since p-value < 0.05, can reject null hypothesis say exist difference means.results , t-test still provides results.Next, continue outliering dataset following functions :IQR*1.5 method: standard method know, recommended use data somewhat symmetric want simple, systematic, robust way outlierIQR*1.5 method: standard method know, recommended use data somewhat symmetric want simple, systematic, robust way outlierPercentile method: recommended skewed data large datasets, also provides flexibility can define thresholdPercentile method: recommended skewed data large datasets, also provides flexibility can define thresholdBecause distributions look fairly different red white wines, outlier free sulfur dioxide separately.Testing outliering based percentiles make analysis different (removed top bottom 5% values).outliering practices provide difference t-test results.going move forward testing analysis alcohol variable. Based distribution alcohol, means spread look relatively (difference small just due fact white wines much data).output , run t-test entire dataset alcohol see difference alcohol means white red wines, get statistical significance. However, makes wonder since means ~10, distribution fairly . practical?Let’s move forward checking outliers make difference:still get statistical significance!due numerous things, stands large sample size low variability, means small difference means can contribute statistical significance. t-test looks ratio difference means variation within groups, low variability can make ratio larger, leading significance. Although test statistically significant, doesn’t seem practically significant since means sd relatively similar- contribute small low effect size. also chance Type Error.","code":"\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(psych)\nlibrary(dplyr)\n# read in data and format\ndir <- \"/Users/rdominguez/MA500/\"\nred <- fread(paste0(dir, \"winequality-red.csv\"))\nwhite <- fread(paste0(dir, \"winequality-white.csv\"))\nsummary(red)##  fixed acidity   volatile acidity  citric acid    residual sugar  \n##  Min.   : 4.60   Min.   :0.1200   Min.   :0.000   Min.   : 0.900  \n##  1st Qu.: 7.10   1st Qu.:0.3900   1st Qu.:0.090   1st Qu.: 1.900  \n##  Median : 7.90   Median :0.5200   Median :0.260   Median : 2.200  \n##  Mean   : 8.32   Mean   :0.5278   Mean   :0.271   Mean   : 2.539  \n##  3rd Qu.: 9.20   3rd Qu.:0.6400   3rd Qu.:0.420   3rd Qu.: 2.600  \n##  Max.   :15.90   Max.   :1.5800   Max.   :1.000   Max.   :15.500  \n##    chlorides       free sulfur dioxide total sulfur dioxide    density      \n##  Min.   :0.01200   Min.   : 1.00       Min.   :  6.00       Min.   :0.9901  \n##  1st Qu.:0.07000   1st Qu.: 7.00       1st Qu.: 22.00       1st Qu.:0.9956  \n##  Median :0.07900   Median :14.00       Median : 38.00       Median :0.9968  \n##  Mean   :0.08747   Mean   :15.87       Mean   : 46.47       Mean   :0.9967  \n##  3rd Qu.:0.09000   3rd Qu.:21.00       3rd Qu.: 62.00       3rd Qu.:0.9978  \n##  Max.   :0.61100   Max.   :72.00       Max.   :289.00       Max.   :1.0037  \n##        pH          sulphates         alcohol         quality     \n##  Min.   :2.740   Min.   :0.3300   Min.   : 8.40   Min.   :3.000  \n##  1st Qu.:3.210   1st Qu.:0.5500   1st Qu.: 9.50   1st Qu.:5.000  \n##  Median :3.310   Median :0.6200   Median :10.20   Median :6.000  \n##  Mean   :3.311   Mean   :0.6581   Mean   :10.42   Mean   :5.636  \n##  3rd Qu.:3.400   3rd Qu.:0.7300   3rd Qu.:11.10   3rd Qu.:6.000  \n##  Max.   :4.010   Max.   :2.0000   Max.   :14.90   Max.   :8.000\nsummary(white)##  fixed acidity    volatile acidity  citric acid     residual sugar  \n##  Min.   : 3.800   Min.   :0.0800   Min.   :0.0000   Min.   : 0.600  \n##  1st Qu.: 6.300   1st Qu.:0.2100   1st Qu.:0.2700   1st Qu.: 1.700  \n##  Median : 6.800   Median :0.2600   Median :0.3200   Median : 5.200  \n##  Mean   : 6.855   Mean   :0.2782   Mean   :0.3342   Mean   : 6.391  \n##  3rd Qu.: 7.300   3rd Qu.:0.3200   3rd Qu.:0.3900   3rd Qu.: 9.900  \n##  Max.   :14.200   Max.   :1.1000   Max.   :1.6600   Max.   :65.800  \n##    chlorides       free sulfur dioxide total sulfur dioxide    density      \n##  Min.   :0.00900   Min.   :  2.00      Min.   :  9.0        Min.   :0.9871  \n##  1st Qu.:0.03600   1st Qu.: 23.00      1st Qu.:108.0        1st Qu.:0.9917  \n##  Median :0.04300   Median : 34.00      Median :134.0        Median :0.9937  \n##  Mean   :0.04577   Mean   : 35.31      Mean   :138.4        Mean   :0.9940  \n##  3rd Qu.:0.05000   3rd Qu.: 46.00      3rd Qu.:167.0        3rd Qu.:0.9961  \n##  Max.   :0.34600   Max.   :289.00      Max.   :440.0        Max.   :1.0390  \n##        pH          sulphates         alcohol         quality     \n##  Min.   :2.720   Min.   :0.2200   Min.   : 8.00   Min.   :3.000  \n##  1st Qu.:3.090   1st Qu.:0.4100   1st Qu.: 9.50   1st Qu.:5.000  \n##  Median :3.180   Median :0.4700   Median :10.40   Median :6.000  \n##  Mean   :3.188   Mean   :0.4898   Mean   :10.51   Mean   :5.878  \n##  3rd Qu.:3.280   3rd Qu.:0.5500   3rd Qu.:11.40   3rd Qu.:6.000  \n##  Max.   :3.820   Max.   :1.0800   Max.   :14.20   Max.   :9.000\nred$color <- \"red\"\nwhite$color <- \"white\"\n\nall <- rbind(red, white)\ndescribe(all)##                      vars    n   mean    sd median trimmed   mad  min    max\n## fixed acidity           1 6497   7.22  1.30   7.00    7.06  0.89 3.80  15.90\n## volatile acidity        2 6497   0.34  0.16   0.29    0.32  0.12 0.08   1.58\n## citric acid             3 6497   0.32  0.15   0.31    0.32  0.10 0.00   1.66\n## residual sugar          4 6497   5.44  4.76   3.00    4.70  2.52 0.60  65.80\n## chlorides               5 6497   0.06  0.04   0.05    0.05  0.02 0.01   0.61\n## free sulfur dioxide     6 6497  30.53 17.75  29.00   29.32 17.79 1.00 289.00\n## total sulfur dioxide    7 6497 115.74 56.52 118.00  115.92 57.82 6.00 440.00\n## density                 8 6497   0.99  0.00   0.99    0.99  0.00 0.99   1.04\n## pH                      9 6497   3.22  0.16   3.21    3.21  0.16 2.72   4.01\n## sulphates              10 6497   0.53  0.15   0.51    0.52  0.12 0.22   2.00\n## alcohol                11 6497  10.49  1.19  10.30   10.40  1.33 8.00  14.90\n## quality                12 6497   5.82  0.87   6.00    5.79  1.48 3.00   9.00\n## color*                 13 6497   1.75  0.43   2.00    1.82  0.00 1.00   2.00\n##                       range  skew kurtosis   se\n## fixed acidity         12.10  1.72     5.05 0.02\n## volatile acidity       1.50  1.49     2.82 0.00\n## citric acid            1.66  0.47     2.39 0.00\n## residual sugar        65.20  1.43     4.35 0.06\n## chlorides              0.60  5.40    50.84 0.00\n## free sulfur dioxide  288.00  1.22     7.90 0.22\n## total sulfur dioxide 434.00  0.00    -0.37 0.70\n## density                0.05  0.50     6.60 0.00\n## pH                     1.29  0.39     0.37 0.00\n## sulphates              1.78  1.80     8.64 0.00\n## alcohol                6.90  0.57    -0.53 0.01\n## quality                6.00  0.19     0.23 0.01\n## color*                 1.00 -1.18    -0.61 0.01\ndescribeBy(all, group = all$color)## \n##  Descriptive statistics by group \n## group: red\n##                      vars    n  mean    sd median trimmed   mad  min    max\n## fixed acidity           1 1599  8.32  1.74   7.90    8.15  1.48 4.60  15.90\n## volatile acidity        2 1599  0.53  0.18   0.52    0.52  0.18 0.12   1.58\n## citric acid             3 1599  0.27  0.19   0.26    0.26  0.25 0.00   1.00\n## residual sugar          4 1599  2.54  1.41   2.20    2.26  0.44 0.90  15.50\n## chlorides               5 1599  0.09  0.05   0.08    0.08  0.01 0.01   0.61\n## free sulfur dioxide     6 1599 15.87 10.46  14.00   14.58 10.38 1.00  72.00\n## total sulfur dioxide    7 1599 46.47 32.90  38.00   41.84 26.69 6.00 289.00\n## density                 8 1599  1.00  0.00   1.00    1.00  0.00 0.99   1.00\n## pH                      9 1599  3.31  0.15   3.31    3.31  0.15 2.74   4.01\n## sulphates              10 1599  0.66  0.17   0.62    0.64  0.12 0.33   2.00\n## alcohol                11 1599 10.42  1.07  10.20   10.31  1.04 8.40  14.90\n## quality                12 1599  5.64  0.81   6.00    5.59  1.48 3.00   8.00\n## color                  13 1599  1.00  0.00   1.00    1.00  0.00 1.00   1.00\n##                       range skew kurtosis   se\n## fixed acidity         11.30 0.98     1.12 0.04\n## volatile acidity       1.46 0.67     1.21 0.00\n## citric acid            1.00 0.32    -0.79 0.00\n## residual sugar        14.60 4.53    28.49 0.04\n## chlorides              0.60 5.67    41.53 0.00\n## free sulfur dioxide   71.00 1.25     2.01 0.26\n## total sulfur dioxide 283.00 1.51     3.79 0.82\n## density                0.01 0.07     0.92 0.00\n## pH                     1.27 0.19     0.80 0.00\n## sulphates              1.67 2.42    11.66 0.00\n## alcohol                6.50 0.86     0.19 0.03\n## quality                5.00 0.22     0.29 0.02\n## color                  0.00  NaN      NaN 0.00\n## ------------------------------------------------------------ \n## group: white\n##                      vars    n   mean    sd median trimmed   mad  min    max\n## fixed acidity           1 4898   6.85  0.84   6.80    6.82  0.74 3.80  14.20\n## volatile acidity        2 4898   0.28  0.10   0.26    0.27  0.09 0.08   1.10\n## citric acid             3 4898   0.33  0.12   0.32    0.33  0.09 0.00   1.66\n## residual sugar          4 4898   6.39  5.07   5.20    5.80  5.34 0.60  65.80\n## chlorides               5 4898   0.05  0.02   0.04    0.04  0.01 0.01   0.35\n## free sulfur dioxide     6 4898  35.31 17.01  34.00   34.36 16.31 2.00 289.00\n## total sulfur dioxide    7 4898 138.36 42.50 134.00  136.96 43.00 9.00 440.00\n## density                 8 4898   0.99  0.00   0.99    0.99  0.00 0.99   1.04\n## pH                      9 4898   3.19  0.15   3.18    3.18  0.15 2.72   3.82\n## sulphates              10 4898   0.49  0.11   0.47    0.48  0.10 0.22   1.08\n## alcohol                11 4898  10.51  1.23  10.40   10.43  1.48 8.00  14.20\n## quality                12 4898   5.88  0.89   6.00    5.85  1.48 3.00   9.00\n## color                  13 4898   2.00  0.00   2.00    2.00  0.00 2.00   2.00\n##                       range skew kurtosis   se\n## fixed acidity         10.40 0.65     2.17 0.01\n## volatile acidity       1.02 1.58     5.08 0.00\n## citric acid            1.66 1.28     6.16 0.00\n## residual sugar        65.20 1.08     3.46 0.07\n## chlorides              0.34 5.02    37.51 0.00\n## free sulfur dioxide  287.00 1.41    11.45 0.24\n## total sulfur dioxide 431.00 0.39     0.57 0.61\n## density                0.05 0.98     9.78 0.00\n## pH                     1.10 0.46     0.53 0.00\n## sulphates              0.86 0.98     1.59 0.00\n## alcohol                6.20 0.49    -0.70 0.02\n## quality                6.00 0.16     0.21 0.01\n## color                  0.00  NaN      NaN 0.00\n# visualize all data transformed from wide to long\nall_long <- melt(all, id.vars = c(\"color\", \"quality\"), measure.vars = colnames(all[,\n    -c(\"color\", \"quality\")]), variable.name = \"property\", value.name = \"value\")\n\nbp_all <- ggplot(data = all_long, aes(y = value)) + geom_boxplot() +\n    facet_wrap(~property, scales = \"free_y\")\nprint(bp_all)\nlibrary(GGally)\nprint(ggpairs(data = all))\n# plot density to see what free sulfur looks like in the\n# whole dataset\ndens <- ggplot(data = all, aes(x = `free sulfur dioxide`)) +\n    geom_histogram(aes(y = after_stat(density)), binwidth = 2,\n        color = \"black\", fill = \"white\") + geom_density(aes(color = color,\n    fill = color), alpha = 0.6)\n\nprint(dens)\n# more visualization to see what the outliers look like in\n# a boxplot\nbp <- ggplot(data = all, aes(x = color, y = `free sulfur dioxide`)) +\n    geom_boxplot()\nprint(bp)\n# run t-test without dropping observations\nt.test(`free sulfur dioxide` ~ color, data = all)## \n##  Welch Two Sample t-test\n## \n## data:  free sulfur dioxide by color\n## t = -54.428, df = 4461.9, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group red and group white is not equal to 0\n## 95 percent confidence interval:\n##  -20.13315 -18.73318\n## sample estimates:\n##   mean in group red mean in group white \n##            15.87492            35.30808\n# t-test when dropping data > 100\nt.test(`free sulfur dioxide` ~ color, data = all[`free sulfur dioxide` <\n    100])## \n##  Welch Two Sample t-test\n## \n## data:  free sulfur dioxide by color\n## t = -55.041, df = 4170.1, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group red and group white is not equal to 0\n## 95 percent confidence interval:\n##  -19.79527 -18.43358\n## sample estimates:\n##   mean in group red mean in group white \n##            15.87492            34.98935\n#' This function processes a data frame, examining all numeric columns\n#' to detect outliers on a row-by-row basis. Since the data being analyzed \n#' is paired, if any observation in a row is considered an outlier \n#' (according to the IQR method), the entire row will be dropped from the dataset.\n#' \n#' @param df A data frame containing numeric columns.\n#' @return A data frame with all rows that had an outlier in any numeric column removed.\n#' \n#' To step through the function line by line, you can add `browser()` \n#' at the start of the function, re-run it, and call a test case. \n#' This will initiate 'debug/browser' mode, allowing you to examine each \n#' step of the function with a snapshot of the environment at that point in time.\ndetect_and_remove_outliers <- function(df) {\n\n    # Create a new column to mark outliers\n    df$is_outlier <- FALSE\n\n    # Loop through each numeric column to detect outliers\n    for (col in colnames(df)) {\n        if (is.numeric(df[[col]])) {\n            # Calculate IQR for the column\n            Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)\n            Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)\n            IQR_value <- Q3 - Q1\n\n            lower_bound <- Q1 - 1.5 * IQR_value\n            upper_bound <- Q3 + 1.5 * IQR_value\n\n            # Identify outliers\n            df$is_outlier <- df$is_outlier | (df[[col]] <= lower_bound |\n                df[[col]] >= upper_bound)\n        }\n    }\n\n    # Remove rows that are outliers\n    df_removed <- df[!df$is_outlier, ]\n\n    # Drop the is_outlier column\n    df_removed$is_outlier <- NULL\n\n    return(df_removed)\n}\n\n# percentile way - may be useful for highly skewed data as\n# IQR might miss values on one tail better for large\n# datasets flexible thresholds\ndetect_and_remove_outliers_percentile <- function(df) {\n\n    # Create a new column to mark outliers\n    df$is_outlier <- FALSE\n\n    # Loop through each numeric column to detect outliers\n    for (col in colnames(df)) {\n        if (is.numeric(df[[col]])) {\n            # Calculate IQR for the column\n            lower_bound <- quantile(df[[col]], 0.05, na.rm = TRUE)\n            upper_bound <- quantile(df[[col]], 0.95, na.rm = TRUE)\n\n            # Identify outliers\n            df$is_outlier <- df$is_outlier | (df[[col]] <= lower_bound |\n                df[[col]] >= upper_bound)\n        }\n    }\n\n    # Remove rows that are outliers\n    df_removed <- df[!df$is_outlier, ]\n\n    # Drop the is_outlier column\n    df_removed$is_outlier <- NULL\n\n    return(df_removed)\n}\n# remove outliers for free sulfur dioxide\nfree_red <- all[color == \"red\", .(`free sulfur dioxide`, color)]\nfree_red <- detect_and_remove_outliers(free_red)\n\nfree_white <- all[color == \"white\", .(`free sulfur dioxide`,\n    color)]\nfree_white <- detect_and_remove_outliers(free_white)\n\n# no difference, obvious difference between groups true\n# significance\nfree <- rbind(free_red, free_white)\n\nfree_dens <- ggplot(data = free, aes(x = `free sulfur dioxide`)) +\n    geom_histogram(aes(y = after_stat(density)), binwidth = 2,\n        color = \"black\", fill = \"white\") + geom_density(aes(color = color,\n    fill = color), alpha = 0.6)\nt.test(`free sulfur dioxide` ~ color, data = free)## \n##  Welch Two Sample t-test\n## \n## data:  free sulfur dioxide by color\n## t = -60.887, df = 4515.2, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group red and group white is not equal to 0\n## 95 percent confidence interval:\n##  -20.12666 -18.87098\n## sample estimates:\n##   mean in group red mean in group white \n##            15.13474            34.63356\n# percentile\nfree_red_percentile <- all[color == \"red\", .(`free sulfur dioxide`,\n    color)]\nfree_red_percentile <- detect_and_remove_outliers_percentile(free_red_percentile)\n\nfree_white_percentile <- all[color == \"white\", .(`free sulfur dioxide`,\n    color)]\nfree_white_percentile <- detect_and_remove_outliers_percentile(free_white_percentile)\n\nfree_percentile <- rbind(free_red_percentile, free_white_percentile)\n\n# the distribution shows the data being more condensed when\n# you outlier based off of a 0.05 threshold\nfree_dens <- ggplot(data = free_percentile, aes(x = `free sulfur dioxide`)) +\n    geom_histogram(aes(y = after_stat(density)), binwidth = 2,\n        color = \"black\", fill = \"white\") + geom_density(aes(color = color,\n    fill = color), alpha = 0.6)\nprint(free_dens)\nt.test(`free sulfur dioxide` ~ color, data = free_percentile)## \n##  Welch Two Sample t-test\n## \n## data:  free sulfur dioxide by color\n## t = -68.652, df = 3886.8, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group red and group white is not equal to 0\n## 95 percent confidence interval:\n##  -20.16152 -19.04195\n## sample estimates:\n##   mean in group red mean in group white \n##            14.98478            34.58652\nbp_a <- ggplot(data = all, aes(x = color, y = alcohol)) + geom_boxplot()\nprint(bp_a)\nt.test(alcohol ~ color, data = all)## \n##  Welch Two Sample t-test\n## \n## data:  alcohol by color\n## t = -2.859, df = 3100.5, p-value = 0.004278\n## alternative hypothesis: true difference in means between group red and group white is not equal to 0\n## 95 percent confidence interval:\n##  -0.15388669 -0.02868117\n## sample estimates:\n##   mean in group red mean in group white \n##            10.42298            10.51427\na_red <- all[color == \"red\", .(alcohol, color)]\na_red <- detect_and_remove_outliers(a_red)\n\na_white <- all[color == \"white\", .(alcohol, color)]\na_white <- detect_and_remove_outliers(a_white)\n\na <- rbind(a_red, a_white)\n# t-test p val is significantly lower\nt.test(alcohol ~ color, data = a)## \n##  Welch Two Sample t-test\n## \n## data:  alcohol by color\n## t = -3.9245, df = 3202.2, p-value = 8.874e-05\n## alternative hypothesis: true difference in means between group red and group white is not equal to 0\n## 95 percent confidence interval:\n##  -0.18272476 -0.06097232\n## sample estimates:\n##   mean in group red mean in group white \n##            10.39242            10.51427\n# only red was affected\nbp_a <- ggplot(data = a, aes(x = color, y = alcohol)) + geom_boxplot()\nprint(bp_a)\n# difference if outliering based off of all data?\nalcohol <- all[, .(alcohol, color)]\nbp_a2 <- ggplot(data = alcohol, aes(x = color, y = alcohol)) +\n    geom_boxplot()\nprint(bp_a2)\nt.test(alcohol ~ color, data = alcohol)## \n##  Welch Two Sample t-test\n## \n## data:  alcohol by color\n## t = -2.859, df = 3100.5, p-value = 0.004278\n## alternative hypothesis: true difference in means between group red and group white is not equal to 0\n## 95 percent confidence interval:\n##  -0.15388669 -0.02868117\n## sample estimates:\n##   mean in group red mean in group white \n##            10.42298            10.51427\ndens_alcohol <- ggplot(data = all, aes(x = alcohol)) + geom_histogram(aes(y = after_stat(density)),\n    binwidth = 2, color = \"black\", fill = \"white\") + geom_density(aes(color = color,\n    fill = color), alpha = 0.6)\nprint(dens_alcohol)\n# try out with smaller sample\nset.seed(123)\nred_sample <- sample_n(red, 150)\nwhite_sample <- sample_n(white, 150)\nsample <- rbind(red_sample, white_sample)\nsample_long <- melt(sample, id.vars = c(\"color\", \"quality\"),\n    measure.vars = colnames(sample[, -c(\"color\", \"quality\")]),\n    variable.name = \"property\", value.name = \"value\")\n\nsample_bp <- ggplot(data = sample_long, aes(y = value)) + geom_boxplot() +\n    facet_wrap(~property, scales = \"free_y\")\nprint(sample_bp)\nt.test(alcohol ~ color, data = sample)## \n##  Welch Two Sample t-test\n## \n## data:  alcohol by color\n## t = -1.0074, df = 295.42, p-value = 0.3146\n## alternative hypothesis: true difference in means between group red and group white is not equal to 0\n## 95 percent confidence interval:\n##  -0.3951196  0.1275640\n## sample estimates:\n##   mean in group red mean in group white \n##            10.41522            10.54900\n# would removing outliers impact?\nsamp_red <- sample[color == \"red\", .(alcohol, color)]\nsamp_red <- detect_and_remove_outliers(samp_red)\n\nsamp_white <- all[color == \"white\", .(alcohol, color)]\nsamp_white <- detect_and_remove_outliers(samp_white)\n\nsamp <- rbind(samp_red, samp_white)\n# does not!\nt.test(alcohol ~ color, data = samp)## \n##  Welch Two Sample t-test\n## \n## data:  alcohol by color\n## t = -1.7234, df = 160.23, p-value = 0.08675\n## alternative hypothesis: true difference in means between group red and group white is not equal to 0\n## 95 percent confidence interval:\n##  -0.31649841  0.02152287\n## sample estimates:\n##   mean in group red mean in group white \n##            10.36678            10.51427\n#' Visualize the distribution of free sulfur dioxide across the three quality \n#' categories. For white wines only, run an ANOVA test to determine if free \n#' sulfur dioxide differs significantly between the three quality groups.\n#' \n\nquality_categorize <- function(x) {\n    if (x %in% 0:4) {\n        return(\"Poor Quality\")\n    } else if (x %in% 5:7) {\n        return(\"Decent Quality\")\n    } else return(\"Great Quality\")\n}\n\nqual_vect <- Vectorize(quality_categorize)\n\nwhite[, qual_category := qual_vect(quality)]\n\ndens <- ggplot(data = white, aes(x = `free sulfur dioxide`)) +\n    geom_histogram(aes(y = after_stat(density)), binwidth = 2,\n        color = \"black\", fill = \"white\") + geom_density(aes(color = qual_category,\n    fill = qual_category), alpha = 0.6)\nprint(dens)\nsummary(aov(`free sulfur dioxide` ~ qual_category, data = white))##                 Df  Sum Sq Mean Sq F value   Pr(>F)    \n## qual_category    2   14485    7242   25.29 1.19e-11 ***\n## Residuals     4895 1401937     286                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nfree_white <- white[, .(`free sulfur dioxide`, qual_category)]\nfree_white_remove <- detect_and_remove_outliers(free_white)\n\nbp_white <- ggplot(data = free_white_remove, aes(x = qual_category,\n    y = `free sulfur dioxide`)) + geom_boxplot()\nprint(bp_white)\nsummary(aov(`free sulfur dioxide` ~ qual_category, data = free_white_remove))##                 Df  Sum Sq Mean Sq F value Pr(>F)    \n## qual_category    2   28262   14131   60.99 <2e-16 ***\n## Residuals     4845 1122522     232                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nwhite[, free_log := log(`free sulfur dioxide`)]\ndens2 <- ggplot(data = white, aes(x = free_log)) + geom_histogram(aes(y = after_stat(density)),\n    binwidth = 2, color = \"black\", fill = \"white\") + geom_density(aes(color = qual_category,\n    fill = qual_category), alpha = 0.6)\nprint(dens2)\nsummary(aov(free_log ~ qual_category, data = white))##                 Df Sum Sq Mean Sq F value Pr(>F)    \n## qual_category    2   58.3  29.145   101.2 <2e-16 ***\n## Residuals     4895 1409.8   0.288                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsamp_white2 <- sample_n(white, 100)\nsummary(aov(`free sulfur dioxide` ~ qual_category, data = samp_white2))##               Df Sum Sq Mean Sq F value Pr(>F)\n## qual_category  2    380   190.0   0.717  0.491\n## Residuals     97  25724   265.2"},{"path":"useful-tips.html","id":"useful-tips","chapter":"Useful Tips","heading":"Useful Tips","text":"","code":""},{"path":"useful-tips.html","id":"outliers","chapter":"Useful Tips","heading":"7.5 Outliers","text":"Outliers can significantly impact model fitting statistical calculations. Always conduct exploratory analysis understand data know context data help determine datapoints outlier .Identifying Outliers R:Use boxplots/scatterplots/histogramsUse boxplots/scatterplots/histogramsfilter data observations > Q3 + .5(IQR) < Q1 - 1.5(IQR)filter data observations > Q3 + .5(IQR) < Q1 - 1.5(IQR)Handling Outliers:1. Understand Cause:Natural Variability: Legitimate data variation.Natural Variability: Legitimate data variation.Data Entry Errors: Mistakes data collection entry.Data Entry Errors: Mistakes data collection entry.Instrument/Process Error: Issues data collection methods.Instrument/Process Error: Issues data collection methods.Decide Approach:\nKeep : reflect true variation.\nTransform Data: Reduce impact.\nCap/Floor Values: Limit extreme outliers.\nRemove : ’re errors irrelevant—document decisions.\nUse Robust Models: Opt models less sensitive outliers.\nKeep : reflect true variation.Transform Data: Reduce impact.Cap/Floor Values: Limit extreme outliers.Remove : ’re errors irrelevant—document decisions.Use Robust Models: Opt models less sensitive outliers.Always document!","code":"-   or by the Z-score method\n\n-   or by percentiles"}]
